{"cells":[{"cell_type":"markdown","metadata":{"id":"C_HqS2nrH1ao"},"source":["# IUST Computer Engineering Department 🏫\n","## Introduction to Natural Language Processing 📚 (The Final Project)\n","### Course Instructor: Dr. Marzieh Davoodabadi Farahani 👩‍🏫\n","### Project Teaching Assistant: Erfan Moosavi Monazzah (tel: @ErfanMoosavi2000) 📞\n","-------------------------------------------------------------------------------<br>\n","The objective of this project is to acquaint you with the fundamentals of Retrieval Augmented Generation (RAG). Be sure to explore various options and address challenges in a creative manner. 🎯\n","\n","**Project Guidelines** 📝\n","- Avoid cheating at all costs. If a set of submissions is found to be [plagiarized](https://translate.google.as/?sl=en&tl=fa&text=Very%20hard%20word%2C%20I%20know%2C%20here%27s%20the%20meaning%3A%0Aplagiarized&op=translate), only one will be randomly chosen for grading. The others will fail the project. ❌\n","- You are allowed to use any document, article, paper, or video as a resource for writing your code, provided you include a link to the material used. 📖\n","- The use of Language Learning Models (LLMs), ChatBots, and Copilots is encouraged. If you utilize any of these tools, make sure to attach the chat history that led you to the answer to your question, or the code, to this .ipynb document. (You must provide the entire chat, not just the final answer or your initial prompt.) 💻\n","- You may not submit any additional documents, files, etc., along with this document. Only solutions, codes, explanations, etc., in this document will be graded. 📄\n","- You are required to implement everything (except the Language Modeling parts) from scratch. The use of libraries like langchain, llama_index, etc., is not permitted for this purpose. 🚫\n","- Please adhere to the code guidelines provided throughout the documents. 📝 I’ve spent time in a library 📚 crafting all of this, so if you overlook them, you’ll lose the points allocated for that section. ❌\n","- We need to use GPUs for this assignment, don't forget to turn on GPU usage for your notebook session.\n","\n","-------------------------------------------------------------------------------<br>\n","# Alright, let's get started. 🚀"]},{"cell_type":"markdown","metadata":{"id":"yDY_VbUpO2Ej"},"source":["## What is RAG? 🤔\n","We've all used ChatGPT and experienced moments when it starts to generate content that is often incorrect or unrelated to our query. Do you know why this happens? These Large Language Models (LLMs) are not magical entities; they are simply models trained on a vast amount of text. 📚 You could even consider a significant portion of the internet. However, this is not all the data available in the world, because data is not a static concept. You yourself generate some data every day through your use of the Internet, Social Media, and so on. 🌐💻📱\n","\n","So, no matter how much data you use to train your LLM, you always end up encountering new data. This is one of the reasons behind the famous ChatGPT response that tells you it only knows things up to a certain date. 📅 Also, these models tend to hallucinate too. It means they provide incorrect answers but in a very convincing manner. 🎭\n","\n","On the other hand, we have retrieval techniques. Don't worry if it sounds complicated (it actually isn't easy, you may need to take a course to familiarize yourself with these concepts 😅, but that's not necessary for this project), but you use it on a daily basis. You can think of Search Engines (like Google, for example) as a complex form of information retrieval. 🔍\n","\n","So, one day, people came up with this idea that it would be cool if ChatGPT could search Google for us, read the articles for us, summarize what it read, and tell us that. 📖 So, this is not exactly what RAG is, but it's something similar. We have a corpus (a large amount of data) and a query (what a user typed as input). Now, we search through this corpus using techniques related to vectors and vector databases, and find the most similar items in our corpus to the query. Then, we pass these items to an LLM and ask for a structured, well-formatted, user-friendly output. 📈📊"]},{"cell_type":"markdown","metadata":{"id":"ljY766adS-vI"},"source":["## I'm Interested in the Technical Details, What Should I Read? 📚🔍\n","- I strongly recommend reading the [original RAG paper](https://arxiv.org/abs/2005.11401). If you need help understanding the paper or have any questions about it, feel free to reach out to me via Telegram or find me on the second floor of the department in the NLP lab on Sundays and Tuesdays. 📖\n","- There appears to be a [comprehensive 2.5-hour course](https://www.freecodecamp.org/news/mastering-rag-from-scratch/) available. I haven't personally watched it, but if you find a better one, let me know so I can update this document. 🎥\n","- Here is [an article](https://www.smashingmagazine.com/2024/01/guide-retrieval-augmented-generation-language-models/) that explains the concepts very well. Initially, I wanted to use this article as the basis for this project, but unfortunately, the llama_index library used in the article seems to be outdated, so most of the code would need to be rewritten. On second thought, I found it more useful to focus on core concepts rather than learning specific libraries. You might want to check out some libraries like langchain or llama_index which provide a lot of tools for RAG. (But not for this project) 📝💡\n","- Don't hesitate to use Google, ask chatbots about any new concepts and terms. If you use search engine-aware chatbots like Microsoft Copilot, they provide links for each part of their answers which is useful if you want to delve deeper into that part. 🌐🤖\n","- Lastly, we have [the article](https://learnbybuilding.ai/tutorials/rag-from-scratch) that serves as the foundation for this project. 📚🔍"]},{"cell_type":"markdown","metadata":{"id":"sYvvT39JXagU"},"source":["# Learn\n","First, we’re going to go through a simple RAG implementation. It’s going to be similar to the article, except for the (LLM) part. For that, I’m going to use Hugging Face. 🤗 I’ll also try to explain the code in simple terms, but feel free to read the article if you prefer their writing style."]},{"cell_type":"markdown","metadata":{"id":"f9eyT0EhN-VX"},"source":["## Let's Install the Necessary Libraries 📚🔧\n","Did you know that using the `--quiet` or `-q` option with the `pip install` command minimizes the output displayed on your screen? 🖥️ This can make your terminal less cluttered. Also, using `-U` will upgrade the libraries if they were previously installed. This is particularly useful for certain libraries like `transformers` that are frequently updated. 🔄"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BeVcIARkHeLg","outputId":"9dd8e23a-7073-4079-d8ef-710d9e5186db","trusted":true},"outputs":[],"source":["!pip install -U accelerate transformers --quiet"]},{"cell_type":"markdown","metadata":{"id":"IjFAILl7cufv"},"source":["## Gather a Corpus 📚\n","Technically, a corpus refers to a large and structured set of texts. However, for the sake of our discussion, let’s consider our collection as a “corpus”, even though it might not be large in the traditional sense. 😉"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G4kOJlPoGNMi","trusted":true},"outputs":[],"source":["corpus_of_documents = [\n","    \"Take a leisurely walk in the park and enjoy the fresh air.\",\n","    \"Visit a local museum and discover something new.\",\n","    \"Attend a live music concert and feel the rhythm.\",\n","    \"Go for a hike and admire the natural scenery.\",\n","    \"Have a picnic with friends and share some laughs.\",\n","    \"Explore a new cuisine by dining at an ethnic restaurant.\",\n","    \"Take a yoga class and stretch your body and mind.\",\n","    \"Join a local sports league and enjoy some friendly competition.\",\n","    \"Attend a workshop or lecture on a topic you're interested in.\",\n","    \"Visit an amusement park and ride the roller coasters.\"\n","]"]},{"cell_type":"markdown","metadata":{"id":"WydRBX1hdKMJ"},"source":["## Create a Retriever 🕵️‍♂️\n","Now, we’re going to create a simple retriever. The role of the retriever is to compare the user’s query with a large corpus of text and find those that are most similar in context. (You know what context is by now, don’t you? 😊 If you’ve forgotten, refer back to your initial lectures). For now, let’s say we want to find similar text based on simple similarity metrics. The code is straightforward, and I have faith in you, chief! Dive into the code. 👨‍💻"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G8Y3bdX_GXqH","trusted":true},"outputs":[],"source":["def jaccard_similarity(query, document):\n","    query = query.lower().split(\" \")\n","    document = document.lower().split(\" \")\n","    intersection = set(query).intersection(set(document))\n","    union = set(query).union(set(document))\n","    return len(intersection)/len(union)"]},{"cell_type":"markdown","metadata":{"id":"iIXWbL47d1WP"},"source":["Hey, you may want to look at wikipedia page for [Jaccard Similarity](https://en.wikipedia.org/wiki/Jaccard_index)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c7XcWPEmGePr","trusted":true},"outputs":[],"source":["def return_response(query, corpus):\n","    similarities = []\n","    for doc in corpus:\n","        similarity = jaccard_similarity(query, doc)\n","        similarities.append(similarity)\n","    return corpus_of_documents[similarities.index(max(similarities))]"]},{"cell_type":"markdown","metadata":{"id":"flgUfa5YeelH"},"source":["## Create a Generator 🖥️\n","Now, we’re going to create a generator. This will help us compile the information retrieved into a well-structured and user-friendly text."]},{"cell_type":"markdown","metadata":{"id":"l4L1NxSlfbZw"},"source":["OK, let's say in a senario, we ask user what they like to do, the their answer is this:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fQK2dTgNGlbN","trusted":true},"outputs":[],"source":["user_input = \"I like to hike\""]},{"cell_type":"markdown","metadata":{"id":"DrBvdcDgfljq"},"source":["Now by using the retrieval model I find this activity that best fits this user."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZI6DXm9kGnVH","outputId":"1b2236a7-2bac-4bfd-e000-9c7d9c0f3d86","trusted":true},"outputs":[],"source":["relevant_document = return_response(user_input, corpus_of_documents)\n","print(relevant_document)"]},{"cell_type":"markdown","metadata":{"id":"zbOKaIVPf5rp"},"source":["The answer seems good enough, but we can do better, yeah?"]},{"cell_type":"markdown","metadata":{"id":"X-Fhu1nugA_l"},"source":["Let’s import a Language Model. I’m going to try out Microsoft Phi-3 because it recently hit the market, and I haven’t had a chance to try it for myself yet. So, I’m seizing this opportunity to do so! 😊👨‍💻"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iblik1cxggpW","trusted":true},"outputs":[],"source":["from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"]},{"cell_type":"markdown","metadata":{"id":"-5Z6xJmZg8d5"},"source":["Downloading the model gonna take a while, use this time to rest your eyes for a bit. 😊👀💤"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":650,"referenced_widgets":["aa0d6e653b8f4b71b6d8fe01428ea88f","c39b392cead34ad2b24c1ce5ddd1c8bb","b0dfc3120c2241d586db487ada828e71","8cceb776ab1a42b4ae9876428d059dc4","bbdc226d8946488896286c4fd5c1a7c9","d500823ecf1c41e88c4d0f4f8f584071","ed917a614dd64ed9a5c46d31d6ca74c1","9a8fc7bcdc414a5dbb285a8a1d27cd25","e0b1bd3bf9984a82b28e9981d443fb0d","465f5ac16bd74b88b16b4bd7ff5c9497","587c82c504dd4d55bd1fec639a857977","6a85fc3710d64488b7fc7cf0bd06bd7f","34ac6ae0852b43498c032f5843c23449","ba099ffa38b8446ab54948377c9cd57c","d55aeabf73e5415bbe1cc70ede979d90","818c89d1c4e24ce5a96688a75a1ef985","2d37b7f7312d48dd8ee6351062219759","c3ab62b3820f49bf8be266770e7ec06c","a5d4ac6578364e81bca94e1dba188e3e","1032f8cb7e9c4a5790dbbffe472d7238","8270f14ba69c43c8b2a9703aebd8adb8","e03ed1c834cd4e7c814d52eab2fbb430","db610c4e5ae34b41afbd1a50cc972469","57a53b6c7f084f98b72628c2b0bd8216","45abbd6a116e47fb872c98ef2208575c","7fd8b7cb971d4a1c8332dd6e4a641f0b","5d859e8d736541d5bb0c0b5b2235517a","7b6098cf2752477fa723e6715a3ae93a","052ad9cc510d482c8fa07c9e80ece598","9ce834fd2c474f9c9661cefec24356be","2adeabc3244d4cd683532701815ab9a1","980f65caa8334b878f8282a90f13de14","0cdc558997ef4d4b908579568dbe37c4","162cb47b55944df8b81318761b6c8b60","6b5113ce36674206b30dfb0b8ca50b15","bf17ae3347944664a0a5ea580479c3fc","21b86c087bd4485abe3b78dfd29ba580","9dc4864e73e24b73944064302de87d80","cd8d7a0cb4464c1a8b867accf9eae933","db15e86f51c744a7812814e07bbb3bcc","3e2105c5dd1941a79d8f9d7e3188cdb9","28341f6d10f34dbb93111d7a8d3cb730","5366f461d0ba465fad3a880dfe9fd930","ec30acf53d6b41609b9b234842850219","77f1c06cedfb49db8e4ebaed8c6eb358","c6340eddece44c559b4941705be86f97","ee97a406ecd341b4a9164a6020ca608f","3e885f22a8f644b8abd2a49224789049","500ab28d94954102a240202d8884d427","d0fee34ef1304249bf635afbfd253f0f","b97e42ee535b47228ba5ade29486ef64","8df04aab0fb440e3b84bc9e3fda8ab64","031b19eeff0441fca6574cf07da92371","ad527ab674a741aeb0f30f0e1708a570","7a488562cc6c4dcab36d8051e1c7549c","f2d67925578f4a7b8e587aca4b3032e5","fc25d899108e487d98cde38b0af8f208","51d28ab174794051b126fdea66f09381","c6612f66dc51428ab4a0abdb90e8791d","0cc0e5d7c1f84c2c9509e354c2b208e7","4380b92f37c14b7b8c880af9931fbe03","d973ef85a8e74e4ca5477522cc083fc4","0620fda80e36439db89bf94c9e8b9a25","bd678dbfb551408f89498f08b7ddf48a","a8d62d58186e4c17b96449478f6476ef","a950e1b94e924a928cba29a14f5f0a94","f3370099e84f499fbb20ac3601929107","1004ea8ba2a748caa30ee0b8f6bdf04c","70aa8f072c6e498db64fc35a156206bb","3ec65b841a15419cb1d6dc039fe457c3","897415366b444ba7b8c3b5eeb06710b8","c660d20e950348a4978b448a5bc358e1","14d0c6cd851a433b92824b1b6f58b3a0","55928b40843b4b78b53388872fb628ea","680142323be24b9893ab81ac28d2086e","bef9341a69a34cacae0fa7e2ba8117e1","c5330e0df04e4077930b08951b0bc89e","bc2452b8820a4d3ca2e77ecd47f49c08","8630bf07eff04738b54801e84fd6e184","90d5f36c957e4822813b121e98bddc97","9cb8568853da42c8859c1479545fafd6","b1a5b800a62f41c095a2e1dba18fbd3f","b377b60174f9429a9228c3fcaebae39c","d6a8bce40f4c4adb9c9319b2a1f4d5e0","e3227be7dc8147e189f8fa2c6d24ae1b","9669836ab33a40c7ae7991d3ef16113e","9a45c2158d2c4b83a8b7200608d4ac4f","c1932b58fb424bb18554fbff43083c39","dd797b33a8ca430bb06ed52c0289724e","69921d76b1bb4abe9108febcaf9ab86a","1d8d8ee1f0b64b8ab9b1d02391373d47","7e729063f4694a05aca30fa31ffbc787","86a216e0a1d64b5e9b88460d353913fa","fb62e196c3ec46608bfffeaa59838a87","bc122f0792c142f88cd05618b990b8d8","855bb723485448acbfe88cfdc2fee482","3166215280164c8f9949840bf50eec67","00d171f2515e4a99941dccce0b880db3","e43f8e723c18441e9f1ae2173f681c61","7a80370d3cb247ebbea40bf0c368e255","d5a53e67539e440583eec9e3297f7b18","e178feca94d44a259c521397688eed1f","c2e1653910504797a190f355c66db5ed","9cc7bc78839d4c3db3682cad996a26cf","4fc9df483d6c4a2b9fd9c3fb47db12ba","e3de92fd49c64c699e4868a6b946a795","5022a47bf4b0424d83030ef119ed4a35","0db620afa09f487081e294c0e29b2d54","9378640159204d25b55089113febef6e","d82c8a449db240aa993ed906f5e32880","b0b01b506bba4006b81da6c7b39630d2","004588b776e44d30a062508032d973b7","6332da23b5be461baeb9e73f7127b04e","7320ada7a0114dab9c8ddf4595ce709e","73e1e3c76a5e44b180f0fef76a80a9d4","8d148fee98174eef8628328f73a2dae3","249aec38b0514ad092354a92be2ac813","55195d9004964d02899f6f500b03a6e9","57f4c95712b1442891dd898a9771e464","ee9062db0d5345b3b602d300f6f98306","4bf2c4ed8a744cdfa4b3381108387320","df021be2b59943d3a2e123f27b5af357","4e3183d233104001a078a7acc59d461b","de2253234ddd4e9a973e715e058bf456","aae84e4dd7af41f493aff6e04aab2e90","1ac3645d77af485f9015e23e6df174ad","83cd503bd2a349a4a5fe88360b07dd9a","38a987a9ab9a40439865b39d29431ac0","39519e4f5ad045d6ba13b11c39ebaeaf","91c7afa2441a4d0a95ae19e9a4a70645","8e74c41b5b0c4872a9ce649fd064ca62","0eae0055584846198ebf9585d041cf79","987ebfb8506c4e4bb9284e1c6cdfb6a1","041c673732684fadaa7bff986d933526","f4b84138d28a42db8093c78574c3323a","962f23bbd63048b998c7a9d9a3e2dc10","05bd5d649b4e480b8a0649db83a624b2","6dedbe5963444cbd84a7c4e2196b2bfe","d756b759dc7a4105bbd1234986556ee5","e6e73602990e4955ab509b5fadd1fcad","c65ce0ba141745dfac30f53e6d862fc5","c5aa191ad0a345ca81b22c79d39c12aa","774c63a738ab4beebafe4c7d0fe9f69f","16e44cffb07143119e7b77e62cca27c9","f6eea78dc7c14a3783cf35a69d4c43e3","2a0709b5d8d24f9c87dc86bd1eea2e6f","6ebe02adfed44fc8b36319cc03e06c8e","5ffbe6c9def64d8797f8de9f0af9a79c","6e619e5265d94d5583862b13334ca37b","eced50764c5d4b1d978a48b025505146","a6e69696d0844d09a1c46f6c9648ace4","f6a67777ab2b425c8fd301188606f5b4","94cec2b157404cbab8a489c79f33123c","1e864dfe67eb4da5b43bc17d177f4acd"]},"id":"xXwZmooeglEq","outputId":"1e4800ad-abf8-4bbe-e922-7ea49b04609d","trusted":true},"outputs":[],"source":["model = AutoModelForCausalLM.from_pretrained(\n","    \"microsoft/Phi-3-mini-128k-instruct\",\n","    device_map=\"cuda\",\n","    torch_dtype=\"auto\",\n","    trust_remote_code=True,\n",")\n","tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-128k-instruct\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EeXXDZ9QjrQf","trusted":true},"outputs":[],"source":["pipe = pipeline(\n","    \"text-generation\",\n","    model=model,\n","    tokenizer=tokenizer,\n",")\n","\n","generation_args = {\n","    \"max_new_tokens\": 500,\n","    \"return_full_text\": False,\n","    \"temperature\": 0.0,\n","    \"do_sample\": False,\n","}"]},{"cell_type":"markdown","metadata":{"id":"uLp-O1cbijgm"},"source":["Now we try to get the LLM to become our generator. We simply place the retrieved information and user query in the following prompt and ask the model for well formatted text."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-BsT-GBmiwww","trusted":true},"outputs":[],"source":["prompt = \"\"\"You are a bot that makes recommendations for activities. Try to be helpful recommender system.\n","This is the recommended activity: {relevant_document}\n","The user input is: {user_input}\n","Compile a recommendation to the user based on the recommended activity and the user input.\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_hgpTsaMjH_b","outputId":"11ce0542-e306-4af9-ea1e-2ac458af4428","trusted":true},"outputs":[],"source":["prompt = prompt.replace(\"{relevant_document}\", relevant_document).replace(\"{user_input}\", user_input)\n","print(prompt)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e9YQcRfwhKI_","trusted":true},"outputs":[],"source":["messages = [\n","    {\"role\": \"user\", \"content\": prompt},\n","]"]},{"cell_type":"markdown","metadata":{"id":"ZZV0Wm6lkJp6"},"source":["Here's the augmented generated text"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pqa6wMSgjxBY","outputId":"fefa58cc-bae9-4d66-8f01-f8c15daa8292","trusted":true},"outputs":[],"source":["output = pipe(messages, **generation_args)\n","print(output[0]['generated_text'])"]},{"cell_type":"markdown","metadata":{"id":"vTMlCH46kNt-"},"source":["## Very Cool, but Not Perfect! 😎👌\n","Alright, you’ve just seen a very basic example of RAG. However, there are some issues present. The corpus is small, and the documents in the corpus are short sentences, which causes the Language Model (LM) to generate some text on its own. 📚🤖\n","\n","Also, our retriever is not very efficient and it may encounter bugs in some cases. For instance, even when users specify that they are not interested in a certain activity, the retriever might still bring up that activity for them. 🐜🔍\n","\n","So, in this project, you’re going to address some of these issues. The rest of this document consists of some empty cells and tips for you on how to fill them with code. Let’s get coding! 👨‍💻🚀"]},{"cell_type":"markdown","metadata":{"id":"UQT1YEx5lgUF"},"source":["# The Project"]},{"cell_type":"markdown","metadata":{"id":"grt_ekxpljUU"},"source":["## Determine Your Task 🎯\n","What do you aim to implement with RAG? A recommender system? 🎁 A chatbot for a website’s FAQ? 💬 A medical advisor? 🩺 Or perhaps something else entirely?\n","\n","Specify your objective in this cell."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wQPvWEXPGyx3","outputId":"51a92cc3-f1c6-4b05-ed87-5a1ed84d7626","trusted":true},"outputs":[],"source":["task_title = \"RAG-based Recommender System for Books\"\n","url_for_more_information = \"https://www.kaggle.com/datasets/jealousleopard/goodreadsbooks\"\n","\n","print(f\"My task is: {task_title}\")\n","print(f'For more information see: {url_for_more_information}')"]},{"cell_type":"markdown","metadata":{"id":"xRXEj5eUmXrr"},"source":["## 🧐 Find or gather a corpus\n","Remember the fake corpus? 📚 It’s time to switch things up and use something real. 🌐 You need to use a dataset from  [huggingface datasets](https://huggingface.co/datasets) for this project. 🚀 Don’t use files that are outside of this notebook, this notebook should be able to run on its own without depending on anything external. 💻👍\n"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Import the load_dataset function from the datasets library\n","from datasets import load_dataset\n","\n","# Load the BookCorpus dataset from Hugging Face Datasets\n","dataset = load_dataset(\"amazon_polarity\")\n","\n","# Display the first few examples from the dataset\n","print(dataset['train'][0])\n","\n","# Print the structure of the dataset\n","print(dataset)\n","\n","# Optionally, explore more examples\n","for i in range(5):\n","    print(f\"Example {i+1}:\")\n","    print(dataset['train'][i])\n","    print(\"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"4-pNcv7WsCNZ"},"source":["## 📝 Create some queries\n","I want you to create 20 queries related to your task. You can use any Language Model you want for this matter, or if you’re feeling strong 💪 and have the time, write it yourself. 🖊️\n","\n","You need to create a Hugging Face account, format your 20 queries into the accepted dataset format for Hugging Face 🤗 and push it to your Hugging Face account. Be sure to make it public and use it for the evaluation task. 👀"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_GZHzDCss-14","trusted":true},"outputs":[],"source":["import json\n","\n","queries = [\n","    {\"query\": \"Recommend me a book similar to '1984' by George Orwell.\"},\n","    {\"query\": \"What are some good mystery novels?\"},\n","    {\"query\": \"Can you suggest a romance book set in Paris?\"},\n","    {\"query\": \"I'm looking for a fantasy book with dragons.\"},\n","    {\"query\": \"Suggest a non-fiction book about history.\"},\n","    {\"query\": \"What are some popular science fiction books?\"},\n","    {\"query\": \"Recommend a thriller with a strong female lead.\"},\n","    {\"query\": \"Can you suggest a children's book about adventure?\"},\n","    {\"query\": \"I'm interested in books about artificial intelligence.\"},\n","    {\"query\": \"What are some classic literature books I should read?\"},\n","    {\"query\": \"Suggest a book that deals with mental health.\"},\n","    {\"query\": \"Can you recommend a good autobiography?\"},\n","    {\"query\": \"I'm looking for a humorous book.\"},\n","    {\"query\": \"Suggest a book that has won a Pulitzer Prize.\"},\n","    {\"query\": \"What are some good dystopian novels?\"},\n","    {\"query\": \"Recommend a book that was turned into a movie.\"},\n","    {\"query\": \"Can you suggest a young adult book series?\"},\n","    {\"query\": \"I'm interested in books about space exploration.\"},\n","    {\"query\": \"What are some good horror novels?\"},\n","    {\"query\": \"Recommend a book with a plot twist.\"}\n","]\n","\n","# Save queries to a JSON file\n","with open('book_recommendation_queries.json', 'w') as f:\n","    json.dump({\"queries\": queries}, f)\n"]},{"cell_type":"markdown","metadata":{"id":"O1TPLIgAnpuA"},"source":["## 🛠️ Create a Retriever\n","To create your retriever, you need to use an encoder model. Something like BERT? Nah, BERT is so yesterday. Find something new and shiny! ✨ The basic idea is to encode every document (sentence) in your corpus into a vector space using the same encoder. Then, encode the user query into that same space. With some similarity metrics like dot product, you can find the most similar document to the user’s input and retrieve it. 🎯 You can train your own encoder if you have enough data and resources, 💪 or you can use one of those [ready-made on Hugging Face](https://huggingface.co/models?pipeline_tag=sentence-similarity&sort=trending), like these ones."]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T10:19:00.526217Z","iopub.status.busy":"2024-06-18T10:19:00.525870Z","iopub.status.idle":"2024-06-18T10:21:45.947693Z","shell.execute_reply":"2024-06-18T10:21:45.946559Z","shell.execute_reply.started":"2024-06-18T10:19:00.526188Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.41.2)\n","Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.30.1)\n","Collecting accelerate\n","  Downloading accelerate-0.31.0-py3-none-any.whl.metadata (19 kB)\n","Collecting bitsandbytes\n","  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n","Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\n","Collecting torch\n","  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n","Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.19.2)\n","Collecting datasets\n","  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n","Collecting sentence-transformers\n","  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.2)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12.1)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.3.1)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n","  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.3.1 (from torch)\n","  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting pyarrow>=15.0.0 (from datasets)\n","  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n","Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.1)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\n","Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\n","Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\n","Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m990.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading datasets-2.20.0-py3-none-any.whl (547 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: triton, pyarrow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, datasets, sentence-transformers, bitsandbytes, accelerate\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 14.0.2\n","    Uninstalling pyarrow-14.0.2:\n","      Successfully uninstalled pyarrow-14.0.2\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.1.2\n","    Uninstalling torch-2.1.2:\n","      Successfully uninstalled torch-2.1.2\n","  Attempting uninstall: datasets\n","    Found existing installation: datasets 2.19.2\n","    Uninstalling datasets-2.19.2:\n","      Successfully uninstalled datasets-2.19.2\n","  Attempting uninstall: accelerate\n","    Found existing installation: accelerate 0.30.1\n","    Uninstalling accelerate-0.30.1:\n","      Successfully uninstalled accelerate-0.30.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 24.4.1 requires cubinlinker, which is not installed.\n","cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cudf 24.4.1 requires ptxcompiler, which is not installed.\n","cuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","dask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n","apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\n","apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\n","apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\n","beatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.1 which is incompatible.\n","cudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\n","cudf 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n","rapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\n","rapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed accelerate-0.31.0 bitsandbytes-0.43.1 datasets-2.20.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pyarrow-16.1.0 sentence-transformers-3.0.1 torch-2.3.1 triton-2.3.1\n"]}],"source":["!pip install -U transformers accelerate bitsandbytes torch datasets sentence-transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T10:21:45.949845Z","iopub.status.busy":"2024-06-18T10:21:45.949540Z","iopub.status.idle":"2024-06-18T10:21:46.260805Z","shell.execute_reply":"2024-06-18T10:21:46.259883Z","shell.execute_reply.started":"2024-06-18T10:21:45.949816Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f5acf09e00f944ab853bd422939b57cc","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"]},"metadata":{},"output_type":"display_data"}],"source":["from huggingface_hub import login\n","\n","login()"]},{"cell_type":"code","execution_count":3,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-06-18T10:24:51.662017Z","iopub.status.busy":"2024-06-18T10:24:51.661314Z","iopub.status.idle":"2024-06-18T10:25:38.645254Z","shell.execute_reply":"2024-06-18T10:25:38.643735Z","shell.execute_reply.started":"2024-06-18T10:24:51.661984Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-18 10:24:59.011341: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-18 10:24:59.011519: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-18 10:24:59.144046: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6d61a44f3baa4ab5bc0a995935cb5273","version_major":2,"version_minor":0},"text/plain":["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"34628826c42f463282cc98bda8154a6f","version_major":2,"version_minor":0},"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"de676616e93049daa4bd2951582c570b","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b19d221ef9c48818b66f6b7592f9419","version_major":2,"version_minor":0},"text/plain":["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fae8d01dc6254c21be4451fcfb46387e","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"785ce6215583476e98e387a782b03550","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2ff2407473cd48ada4f14e495bf85cf2","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b8955461f5754bc9a4a560d4ebab95b8","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6466bb25da444904b8bbcacf56ca7bfd","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fe7941cd01b94843a8a0850f9eb0e8a0","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"929ce0cc3327458bbc51683aca56cac8","version_major":2,"version_minor":0},"text/plain":["1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3bb0c48f3fa54a9e976f1651fd601130","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/6.81k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eb9bd8ff6fc649da80650f18bb8a31aa","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/260M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"01aa4eb4807d46a580c505ca44ed15a1","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/258M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c7427bf034fb4910a589d0856a8049cf","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/255M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e6d999bd50442ba84de3ad71c8f17bc","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/254M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"40e8e17249bc4278b93588c7a3f12a4f","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/117M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5fee70eed239477586c859603e1b9bc7","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/3600000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9a9361cef815467d8dd19993d086502e","version_major":2,"version_minor":0},"text/plain":["Generating test split:   0%|          | 0/400000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6187911ae6b941f8b2ec4eedd111a64b","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/63 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"95230344a9b640ecaafaba8a34406ad1","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Query: Recommend me a book similar to '1984' by George Orwell.\n","Score: 0.5647\tDocument: This is truely an amazing book, Aldous Huxley was a genius. Although different from BNW in that the plot is a little slow, the ideas of society and the individual expressed in this book make it one of the most influential books that I ever read. Don't read this book to be entertained, read it to be enlightened.\n","Score: 0.5585\tDocument: I absolutely loved this book! Eckhart Tolle in \"The Power of Now\" actually references this book and that is how I heard of it. Despite the fact that much of the book is ruled by long monologues from the characters, I enjoyed it all. Huxley had an interesting view of what a society can become when it takes the best of the Eastern and Western worlds combine.\n","Score: 0.5200\tDocument: Excellent and well-written book. Recommended reading for young adults and older. We must all remember what atrocities were committed in Europe and other countries. It is a testament to the human spirit and the capacity to survive terrible circumstances. This book will become a permanent part of our family's library.\n","Score: 0.5105\tDocument: It is astounding that anyone in this age can seriously recommend this book. It has no bearing on the world economy and is blatantly anti labor and anti government regulation. It is hopelessly out of date.\n","Score: 0.5053\tDocument: This book is a very informative, yet easy read about the realities of life and how patterns are repeated sometimes even unknowingly until honestly addressed and changed. That is where the power of this book lies in giving insight, tools, all with a touch of humor to make positive changes of direction in our lives. Highly recommend.\n","\n","\n","Query: What are some good mystery novels?\n","Score: 0.5949\tDocument: This was my first Patricia Cornwell novel and I must say I was blown away. I never thought I'd warm up to a modern mystery writer the way I did with Agatha Christie and Dorothy L. Sayers, but Ms. Cornwell has displaced them both in my heart.C & E was by far the most fascinating book I've ever read. I sat up until the wee hours of the morning reading this wonderful novel, devouring every word, as I couldn't go to bed until I had finished it. The only disappointment was the ending. The killer came out of the blue, and there were too many loose ends.The story and characters were first rate and I intend to read all her other books. It's been a long time since I found an author I would be willing to pay hardcover prices to read.\n","Score: 0.5861\tDocument: I have read all Patricia Cornwell's book, and I think Ms. Cornwell has reached her best in writing this book.Suspense, mystery, New York, they all contribute to keep you awake until you finish the book.\n","Score: 0.5848\tDocument: This book was a major disappointment. It was missing that special spark that made Ms Feehan's other novels (especially Dark Desire) something special. I found the book had very little action, little romance, and a \"mystery\" plot that was never very mysterious or suspenseful. This is definitely not a book that I will pass on to my friends and family to read.\n","Score: 0.5735\tDocument: DAUGHTERS OF DARKNESS was the first book by L. J. Smith that Iread and I was hooked after that! I loved the way L. J. Smithdescribed all the characters, especialy Ash, and gave them all completely different personalities. This is, by far, one of the best books I've ever read and I can't wait for STRANGE FATE to come out. For anyone who is looking for another good series by L. J. Smith I suggest the Vampire Diaries and Dark Visions trilogies.\n","Score: 0.5675\tDocument: The Scarletti Curse is absolutely wonderful. Ms. Feehan once again created a lively well written work that stand far apart from her Dark series (which I also adore). With complex and dark characters this book has quite a lot of bite and more than enough romance for a true fan of Christine's work. I highly recommend this book for one and all.\n","\n","\n","Query: Can you suggest a romance book set in Paris?\n","Score: 0.5469\tDocument: I just finished reading Whisper of the Wicked saints. I fell in love with the caracters. I expected an average romance read, but instead I found one of my favorite books of all time. Just when I thought I could predict the outcome I was shocked ! The writting was so descriptive that my heart broke when Julia's did and I felt as if I was there with them instead of just a distant reader. If you are a lover of romance novels then this is a must read. Don't let the cover fool you this book is spectacular!\n","Score: 0.5351\tDocument: This is an engaging a count of life of Tess a girl who at a young age washed up on the shore of the Isle of May. With no memory of the life before then, she stays with the old caretakers of the isle. After the caretakers are dead a young man, Colin Macpherson washes up on shore. Colin takes Tess back with her to his castle where he helps her uncover her past. They are opposites,but you know what they say opposites attract. This book is just one of many in the Avon True Romance series. I have read every book in the series and I know that if you like this book you love the rest. This is a great book for girls about 10 to 16 because it is still a romance novel, but not what you call a trashy romance novel. It is a great novel fokr those who are just getting into romance novels.\n","Score: 0.5326\tDocument: If you are looking for something that entertains, tells a great story, and inspires you to want to go to Italy and fall in love with someone (or with the food) this is the perfect book. I recommend it as mandatory reading for all groups I bring to Italy. All who have read it, especially women, love it.\n","Score: 0.5264\tDocument: I have really enjoyed Ms. Feehan's Dark series, so was eager to read her new book. This is a true gothic with just enough paranormal elements to help build a relationship between the hero and heroine. Nicoletta has special \"gifts\" which her entire village tries to keep a secret, however, it is the presence of these gifts which draws Don Scarletti to her. He has \"gifts\" of his own. Nicoletta isn't immediately enchanted with the idea of marriage to the Don. Unlike some authors, who use the \"I hate you!\" temper tantrum to ignite passion between the main characters, Ms. Feehan uses the empathy and sensitivity of her characters to achieve it. The love scenes are wonderful, though not very plentiful. So if you're looking for the same amount and intensity of love scenes as in the Dark books, you may be dissappointed. I read this in one sitting and couldn't put it down. The story is riveting.\n","Score: 0.5254\tDocument: All I can really say is I didn't even finish the book. I love romances but this one wasn't for me. I found it too much to read about sexual desire and how the body responds to it, that was too much for me. I would say this book should say blush or some kind of note to let people know its not clean romance.\n","\n","\n","Query: I'm looking for a fantasy book with dragons.\n","Score: 0.5525\tDocument: The book Castle in the Attic is a good book.My favorite part is when william defeated Alastor. There was one other good part in Castle in the Attic. When William was trying to get to Alastors kingdom and the dragon was distracting him with bad visions. I recommend this book to anybody who likes exciting books.\n","Score: 0.4856\tDocument: I had been looking for this book for years. I read it as a child and wanted to have it. Thank you so much for a great vintage copy!\n","Score: 0.4643\tDocument: While this book is a take-off on the classic Snow White, it's a fairytale for grown ups with some class act characters and a rich and rewarding love story. I thoroughly enjoyed reading it, and look forward to more of Ms. Sinclair's works.\n","Score: 0.4624\tDocument: I liked the book Castle In The Attic because it was a book on a Dragon and a Knight. My three favorite parts were when William climbed the tree and got the apple for the cursed man. My other one was when he fought the dragon,and my last one was when William fought Alastor.Other kids should read this book so they will be more interested in reading the sequel Battle For The Castle.\n","Score: 0.4450\tDocument: This is one of the funniest books that I've encountered in some time. All Harry wants to do is take a little boat trip, maybe do some fishing, and relax. If page one is an indication of the things to come, it's not good news for Harry. We see a seagull trying to break open a clam shell by dropping it on Harry's head. He gets caught in a storm and is stranded on an island with a lot of rocks, a scraggly tree, and an egg. As the egg hatches Harry figures it must be a bizzard, but comes to the realization that it's actually a dragon, a dragon that is continually eyeing Harry going \"Mmmmmmmmmmm\". The ending is a delightful twist and a valuable lesson is learned--there are fates far worse than death.Don't pass this book up. A good number of titles out there can have the reader laughing on the first page but, can't deliver. This one does.Poor Harry!!!\n","\n","\n","Query: Suggest a non-fiction book about history.\n","Score: 0.5363\tDocument: Once you get past the language barrier, this book is an amazing read. To see the tragedies that some women went through at one point in history is a great thing, and to remind us never to let history repeat itself.\n","Score: 0.4878\tDocument: What a disappointment. This book is about 50% self-centered travelogue and 50% teasers about the mysteries. I expected a book full of archeological information about cities and cultures that have long since disappeared, but instead got embarrassingly ridiculous chit-chat and superficial explanations. I wanted scientific information, not a book that tends to explain most of its mysteries via levitation and alien beings!\n","Score: 0.4865\tDocument: To read this book you need to be fully awake and have full concentration. This is not the type of book to bring to the beach. Though Richard Hofstadter makes a convincing case of what colonial times were like and he obviously was a scholar, he writes very monotonously. if not thouroughly interested in american history at 1750 i would not recommend this book. otherwise, if you are a history-fanatic, this book gives a wide range of perspectives and fully covers the history of the time.\n","Score: 0.4810\tDocument: This is one of the all-time most boring books. I do not recommend reading it at all. The introduction is incredibly long, and incredibly boring. Also, it doesn't really have the sort of plot that would make it a book you can't put down. I personally fell asleep four different times reading this book. I had much higher expectations for this book. If you are looking for a classic to read, I would recommend The Count Of Monte Cristo, not this book.\n","Score: 0.4806\tDocument: Excellent and well-written book. Recommended reading for young adults and older. We must all remember what atrocities were committed in Europe and other countries. It is a testament to the human spirit and the capacity to survive terrible circumstances. This book will become a permanent part of our family's library.\n","\n","\n","Query: What are some popular science fiction books?\n","Score: 0.4259\tDocument: Well paced novel with interesting characters and plenty of plot twists. Patricia Cornwell writes characters that are real and have depth. Her mastery of criminal science is wonderful and offers a sense of authenticity that few authors achieve.\n","Score: 0.4181\tDocument: What a disappointment. This book is about 50% self-centered travelogue and 50% teasers about the mysteries. I expected a book full of archeological information about cities and cultures that have long since disappeared, but instead got embarrassingly ridiculous chit-chat and superficial explanations. I wanted scientific information, not a book that tends to explain most of its mysteries via levitation and alien beings!\n","Score: 0.4099\tDocument: I loved Patricia Cornwell's first five novels; sadly, her sixth loses its edge.. I wanted to enjoy it.. but the plot labors on.. and I had a hard time finishing a book I couldn't wait to read. We lose Scarpetta's forensic \"grit\" and instead focus on a bizarre, rather boring computer plot.. I hope the next books in the series are better!\n","Score: 0.4086\tDocument: As light weight sci-fi/horror anthologies go this is probably good value for money (given its low price), but the apparent lack of good editing and of proper proof reading is painfully evident and you definitely won't find any candidate for a Hugo or Nebula award.You'll find a couple of interesting ideas, a lot of trite and derivative ones and occasionally some baffling lack of coherent character development.There's enough to show that Messrs. Jason Brannon, Eric S. Brown and John Grover have the potential to write something good, but it seems to be, at the moment at least, unfulfilled potential.\n","Score: 0.4065\tDocument: Cruel and Unusual is the first Patricia Cornwell book I have got read and I for one loved it and I can't wait the read more of her books my boyfriend told me about Patricia Cornwell books he said I need to read Hornet's Nest and Southern Cross and those will be my next two book I will be reading and I will be reading them on my new IPad I got for Christmas I can't wait keep up the great writing Patricia and thanks to my boyfriend for telling me about this awesome writer.........RKsbabydoll\n","\n","\n","Query: Recommend a thriller with a strong female lead.\n","Score: 0.5903\tDocument: This supposed \"thriller\" is mind-numbingly dull and inept - I had to give up half way through.\n","Score: 0.4832\tDocument: First, let me say, I'd heard that I might find the Dark Series of Christine Feehan's my cup of tea and for some unknown reason, thought this was one in the series - no need to tell you, I was severely disappointed (and confused).This book really reminded me of the romances my Mother used to read back in the 70's - blech! Lots of dark male broodiness, all written from the heroines point of view, and of course she's a young innocent virgin._____________edited to add: I really wish I had only given this one star, but it appears I can't change that now.\n","Score: 0.4816\tDocument: This is one of the worst written books I have ever read.I wish I had saved my money and my time.The book is full of superlatives. Everything is \"the best ever experienced\" again and again.The characters NEVER become embraceable. One male character is pathetic while the other is a jerk. The female lead is portrayed as perhaps innocently unaware, but is really just stupid. Her friend is promiscuous, which is all we ever really get to know of her.The writing is at a level well below that of an adult reader. But, the content could not possibly be meant for a younger reader. Very inappropriate.Not sure who would really like this book.Maybe someone who really likes descriptions of food and does not care about plot, story development, characterization or any other facets of literature.Find yourself something with a little more substance, and I think you'll be much happier.\n","Score: 0.4763\tDocument: I really like Christine Feehan. This book was very dissapointing. The plot had promise. Nicoletta was a sweet heroine. The prose were good, and the medival Italy setting was an interesting change of pace. However, the plot flows like molasses in January. I managed to get half way through before I through the book down and went back to the 'Dark' series.\n","Score: 0.4544\tDocument: A typical Patricia Cornwell fiction novel, easy to read and a page turner. It gripped me until the end. Enjoy.\n","\n","\n","Query: Can you suggest a children's book about adventure?\n","Score: 0.6388\tDocument: This book is amazing. I read it when I was a child and couldn't put it down. It has amazing adventure and suspense, without the horrible violence. Several months ago, something reminded me of the book and I had to hunt it down. I had forgotten the title and the author(it had been 15 years since I read it). I finally was able to locate it. I was thrilled. I bought it and read it in just a couple of hours. It is a book I recommend for both children and adults.\n","Score: 0.6083\tDocument: \"Castle\" is a wonderful book for children who have short attention spans. It provides adventure and re-affirms the laws of chivalry.\n","Score: 0.5999\tDocument: In the beginning, William is an ordinary boy, but when his toy knight comes alive, and William shrinks, the adventure begins. This book was one of the best books I've ever read. And anyone with a big imagination and a love for adventures will love this book too.\n","Score: 0.5554\tDocument: These books are the best. My kids all under 5 love them. They are so easy to understand that you don't need to be there to explain or read what they are looking for it shoes the picture for them. I'm defiantly going to buy more.\n","Score: 0.5446\tDocument: My children and I love the little Critter books. This is a great book, but it was not bound well. The book fell out of the cover within a few days of recieving it.\n","\n","\n","Query: I'm interested in books about artificial intelligence.\n","Score: 0.3936\tDocument: \"Easy A\" explains it best. If you can't relate in some way you must be a robot. Greatest book ever.\n","Score: 0.3912\tDocument: This book was purchased for a PhD level course. It is a very easy read. It gives practical applications to the latest brain research. On a down note, there are not a lot of references documented within the text when Jensen quotes a study, but he does give an extensive bibliography. This book can be used for parents to read about how their child's brain works, or for teachers within a school system. It is a good book to read if you want basic information about the brain from an education standpoint.\n","Score: 0.3645\tDocument: The book contains 280 pages of text, 25 pages of refenreces, 7 pages of INDEX, and many figures and cartoon to explain the concept of author's hypothesis. Barbieri was a development biologist at MRC in Cambridge, NIH, and Max Planck.This is a typical anti-Darwinism semi-pseudoscience book. I picked up the book because the book cover had a Chomsky's accolade. It's not as obvious and outrageous as Intelligent Desing-sort of book, but the author cites his own book to explain his main points. Many biological facts in the book are real and correct, but there is no scientific logical structure to support the author's \"semantic\" theory. I was struck by the fact that this book was published from Cambridge University Press.\n","Score: 0.3478\tDocument: Book is a great read. Intriguing from start to finish. Cant find anything wrong to say. Would reccomend for beginer to advanced readers.\n","Score: 0.3455\tDocument: A good book for Audi owners, and fans in general.The book dosen't just focus on the quattro itself, but the surrounding models as well.Not too much of a technical book, but more of an enthusiasts read.\n","\n","\n","Query: What are some classic literature books I should read?\n","Score: 0.5835\tDocument: To me this book would turn a young person, like my self away from the key and enjoyment of reading . Being a book with extensive mistakes in it, it is very difficult to read unless you are to inerpret it every paragraph or should I say sentence. I't maybe a classic, but I feel that the word \"classic\" comes from just being old........................................................................................................p.s the only reason I put a star was because I had to, to express my opinion on he novel.\n","Score: 0.5783\tDocument: This is one of the all-time most boring books. I do not recommend reading it at all. The introduction is incredibly long, and incredibly boring. Also, it doesn't really have the sort of plot that would make it a book you can't put down. I personally fell asleep four different times reading this book. I had much higher expectations for this book. If you are looking for a classic to read, I would recommend The Count Of Monte Cristo, not this book.\n","Score: 0.5679\tDocument: Frankly, in reading the negative reviews it is clear to me that there is a growing body of illiterates among us. It seems too, that the more a book makes one think the more negaive review it receives from some readers.I do agree that this particular Kindle edition is cumbersome to navigate due to the format but it is still an exceptional book and very worth reading. Not only is the character developmet quite thorough and enjoyable but it gives us a glimpse of the society in which it was written. What I always find fascinating is that this, like most other classics, is about human nature, power and the consequences of actions. So in the end these themes are enduring and feed our desire to look into the hearts and souls of others- to be voyeurs-which is what makes a classic a classic.\n","Score: 0.5601\tDocument: A classic? Hardly. In it's time this book may have ruffled feathers but these days it's a struggle to get through. Hawthorne's writing style is dreary and dreadful; if captivating readers was his aim, he failed miserably.\n","Score: 0.5587\tDocument: This book is a masterpiece of not only American literature, but of world literature. Reading this book was the experience that showed me what good literature is. This is easily in my top three along with Fahrenheit 451 and The Adventures of Huckleberry Finn.\n","\n","\n","Query: Suggest a book that deals with mental health.\n","Score: 0.4648\tDocument: I got nothing out of this book. I've read many self-help books, and this is among the worst. McWilliams provided worn-out cliches, and the book reads slowly. If you want good selp-help books, check out Denis Waitley and Anthony Robbins.\n","Score: 0.4260\tDocument: I got this book from the library yesterday and read it cover to cover in 24 hours. It is a wonderful coming-of-age book dealing with loss of innocence, and brings back all the physical and emotional feelings that come with puberty. Family dysfunction is dealt with in typical '60's style -- no over-analyzing or self-pity was allowed then!\n","Score: 0.4161\tDocument: This book was purchased for a PhD level course. It is a very easy read. It gives practical applications to the latest brain research. On a down note, there are not a lot of references documented within the text when Jensen quotes a study, but he does give an extensive bibliography. This book can be used for parents to read about how their child's brain works, or for teachers within a school system. It is a good book to read if you want basic information about the brain from an education standpoint.\n","Score: 0.4005\tDocument: I read this book for my 11th grade Lit class and I must admit the book was quite a shock. Many of the books I have read have been nothing more than an attempt at delving into the inner parts of the human soul. This book does much more than that. It depicts the struggle of a man with himself and an outside enemy. He commits one of the most unspeakable acts of the time and punishes himself constantly. He lacks the courage to confess his crime and goes through a period of mental and physical torture. He also faces the wrath a cruel and vicious enemy who lives for nothing more than to torture his victim. All in all I believe it was an excellent book and I would reccomend it to anyone.\n","Score: 0.4004\tDocument: This book is a very informative, yet easy read about the realities of life and how patterns are repeated sometimes even unknowingly until honestly addressed and changed. That is where the power of this book lies in giving insight, tools, all with a touch of humor to make positive changes of direction in our lives. Highly recommend.\n","\n","\n","Query: Can you recommend a good autobiography?\n","Score: 0.5063\tDocument: This book is not well written and leaves nothing to the imagination. If I hadn't bought it in hard cover and spent the money I would not even have finished reading it.\n","Score: 0.4998\tDocument: I ordered this book as part of a third grade curriculum for my son. These Everyman titles are really wonderful-- beautiful binding, heavy pages, amazing illustrations. I was not disappointed with this book. It is the kind of book we will read again and again and hopefully pass on to the next generation. Hawthorne's rendition of the myths and fables is classic and engaging, and Rackham's illustrations are worth the price on their own.\n","Score: 0.4974\tDocument: Well-made book. Informative with excellent photography. The overall layout is quite conducive to interrupted reading - easy to pick up and start anywhere.\n","Score: 0.4881\tDocument: For a first time reading of this classic I recommend this. If you love it you may want a nicer version for the bookshelf. This is a nice quality book though. The printing isn't too small, and neither is the book. It fits right in my paperback bookshelf perfectly with others just like it.And as for the story, I could go on many pages. Just do a few searches for reviews, it's a classic that will outlive all of us and has a lot to say about human beings and our culture, past and future.One of the best Classics, great one to get started on or to read over and over again.\n","Score: 0.4862\tDocument: I loved the way the author brought in stories of various children. I felt like I got to know the children throughout their stages of development. A great textbook!\n","\n","\n","Query: I'm looking for a humorous book.\n","Score: 0.6427\tDocument: This book is laugh-out-loud funny, a great read and romantic enough to keep me turning the pages. I couldn't put it down!\n","Score: 0.6156\tDocument: A quick, light-hearted read that kept my attention from beginning to end. Not the kind of book I usually read, although I'm glad I took the time to give this one a whirl. Definitely good for a few chuckles.\n","Score: 0.5776\tDocument: I love books that make me laugh, and a friend told me about this book. I paid full price, and I feel somewhat had. Ms. Jensen has a gift for humor, but the plotting involved in this book is horrible. Good humor has to have some element of believability in it, and this book has none whatsoever. With a believable story line, Ms. Jensen could be among the top humor writers out there.\n","Score: 0.5558\tDocument: I had been looking for this book for years. I read it as a child and wanted to have it. Thank you so much for a great vintage copy!\n","Score: 0.5426\tDocument: I didn't find this book at all interesting.. all though there was occasional humor.. in general, i didn't enjoy this piece of literature.\n","\n","\n","Query: Suggest a book that has won a Pulitzer Prize.\n","Score: 0.4687\tDocument: A typical Patricia Cornwell fiction novel, easy to read and a page turner. It gripped me until the end. Enjoy.\n","Score: 0.4652\tDocument: I have read all Patricia Cornwell's book, and I think Ms. Cornwell has reached her best in writing this book.Suspense, mystery, New York, they all contribute to keep you awake until you finish the book.\n","Score: 0.4498\tDocument: This book is a masterpiece of not only American literature, but of world literature. Reading this book was the experience that showed me what good literature is. This is easily in my top three along with Fahrenheit 451 and The Adventures of Huckleberry Finn.\n","Score: 0.4493\tDocument: This book is amazing. Its year-by-year descriptions are historical and often suspensful. I remember the first time I read this book, before I knew the outcome of many of the years' awards; each year was a new drama with Mr. Wiley and company setting up the atmosphere of the race. Now, fifteen years later, I own the latest edition of Inside Oscar. It is a constant source of amusement and information. The writing is skillful and clever, and the categorical listing at the back is an invaluable reference. Every year during Oscar season, I will pick up an article by some journalist whose grasp of Oscar history is minimal, and I wonder why they don't just look up who REALLY won in Inside Oscar. I know Mr. Wiley is no longer with us, but I hope Mr. Bona and company continue the great work for future editions. I know I'd love to be a contributor to this tremendous work.\n","Score: 0.4381\tDocument: This book was dull non for feeling non inspiring boring made no sense. I would not recomended this book to a friend it is terrible. I rather read something else rather than this book\n","\n","\n","Query: What are some good dystopian novels?\n","Score: 0.5632\tDocument: A typical Patricia Cornwell fiction novel, easy to read and a page turner. It gripped me until the end. Enjoy.\n","Score: 0.5521\tDocument: Well paced novel with interesting characters and plenty of plot twists. Patricia Cornwell writes characters that are real and have depth. Her mastery of criminal science is wonderful and offers a sense of authenticity that few authors achieve.\n","Score: 0.5306\tDocument: I absolutely loved this book! Eckhart Tolle in \"The Power of Now\" actually references this book and that is how I heard of it. Despite the fact that much of the book is ruled by long monologues from the characters, I enjoyed it all. Huxley had an interesting view of what a society can become when it takes the best of the Eastern and Western worlds combine.\n","Score: 0.5275\tDocument: My english teacher assigned this book, one I would never read on my own. I am a 16 year old and I enjoy reading. But this book, while it does have a few good points and messages, is incredibly dull. The points are hard to get and I only understood the points after we had discussed them in class. While this book has a rather good story it`s concealed by endless symbols and references, I suggest the cliff notes version!!\n","Score: 0.5260\tDocument: I loved this book in high school, and I love it now. A tale of a strong woman that doesn't let society bring her down.\n","\n","\n","Query: Recommend a book that was turned into a movie.\n","Score: 0.5944\tDocument: Loved this book as well. The movies as always stray from the book- I was pleasantly surprised and taken in by all the characters.\n","Score: 0.5546\tDocument: This is without a doubt Higgins' least inspired work in years. The plot is predictable and over worn, and the books is very uninspired. A real disappointment\n","Score: 0.5423\tDocument: Great book, had seen the movie but the book is much more. It will hold your attention and is an easy read too.Even better, the e-book was free on Amazon!\n","Score: 0.5311\tDocument: Must have movie,Must have, inspiring, enlightening, eye opening, good, heart felt enlightening, must have in your own library, movie to keep and give\n","Score: 0.5188\tDocument: Boy, this was a disappointing read. The characters were not well developed (hence challenging to keep track of), the plot was implausible yet predictable, and half way through I had to wrestle with whether or not to even finish the book. I did, although it was unrewarding to do so.I'd rate this lower if I could.FYI, if you're looking for an alternate selection in the same genre, I highly recommend Silent Joe by T. Jefferson Parker.\n","\n","\n","Query: Can you suggest a young adult book series?\n","Score: 0.5959\tDocument: DAUGHTERS OF DARKNESS was the first book by L. J. Smith that Iread and I was hooked after that! I loved the way L. J. Smithdescribed all the characters, especialy Ash, and gave them all completely different personalities. This is, by far, one of the best books I've ever read and I can't wait for STRANGE FATE to come out. For anyone who is looking for another good series by L. J. Smith I suggest the Vampire Diaries and Dark Visions trilogies.\n","Score: 0.5856\tDocument: The Xanth series is what got me reading sci-fi and fantasy novels. Its a shame this series has turned into unreadable mush.Zombie Lover was the last book I've bought in this series and I don't think I'll continue with it. I can't take in anymore stories of adolescents thinking about who they want or don't want to have sex with.\n","Score: 0.5353\tDocument: Daughters of Darkness is the best yet!! I happened to pick it up by mistake in the Library and I Got hooked right away! I must have read it 50 times!! I loved the way Ash Tried to protect her from Jermey but she saved herself. I really hope there's another book on those two!\n","Score: 0.5322\tDocument: This book is amazing. I read it when I was a child and couldn't put it down. It has amazing adventure and suspense, without the horrible violence. Several months ago, something reminded me of the book and I had to hunt it down. I had forgotten the title and the author(it had been 15 years since I read it). I finally was able to locate it. I was thrilled. I bought it and read it in just a couple of hours. It is a book I recommend for both children and adults.\n","Score: 0.5170\tDocument: Book is a great read. Intriguing from start to finish. Cant find anything wrong to say. Would reccomend for beginer to advanced readers.\n","\n","\n","Query: I'm interested in books about space exploration.\n","Score: 0.4868\tDocument: What a disappointment. This book is about 50% self-centered travelogue and 50% teasers about the mysteries. I expected a book full of archeological information about cities and cultures that have long since disappeared, but instead got embarrassingly ridiculous chit-chat and superficial explanations. I wanted scientific information, not a book that tends to explain most of its mysteries via levitation and alien beings!\n","Score: 0.4584\tDocument: The book CARIBES is the second in a series of six books by Alberto Vasquez-Figueroa. The first book being, CIENFUEGOS I, which was an exceptional book that I couldn't put down once I began reading it. The tradition follows with CARIBES, although not as exciting as the first book, this book continues to entertain and makes you laugh, as well as giving you factual knowledge about the discovery of the \"new world.\" Highly recommended. I just wish that Amazon had all six books (cienfuegos, caribes, montenegro, azabeche, xaragua - and one more that I can't remember off hand).\n","Score: 0.4096\tDocument: This is a text book I ordered for my classes for teacher certification. This book is very easy to read, and I am really enjoying it. It presents info and then at the end of a section, recaptures the essence of the reading for you. I would suggest it for any teaching class. I am learning so much from this book. I have been buying all my text books from Amazon because they are so much cheaper, and sometimes I can get free shipping. So far, there has not been a book that I could not find here at Amazon.\n","Score: 0.3949\tDocument: Book is a great read. Intriguing from start to finish. Cant find anything wrong to say. Would reccomend for beginer to advanced readers.\n","Score: 0.3897\tDocument: This was one of my favorite books assigned in school this year. I like the exciting adventures of this cannon trek from Fort Ticonderoga to Cambridge, MA. I liked how they crossed the ice with all of those big guns. When the last gun crossed, the ice cracked, but they were able to get the big gun out.\n","\n","\n","Query: What are some good horror novels?\n","Score: 0.6391\tDocument: How can anyone like this book??? its got to be the worst horror book I have ever read and I normaly like a good horror book now and then. I mean most Horror books or movies give me the creeps this one I could resd in the scaryest place in the world yaw and go to sleep. got to be the worst book ever writen by the way I am 13 just dont wana give out my account name on here later\n","Score: 0.5969\tDocument: You have to love the Scarpetta series by Cornwell. This is an excellent story full of suspense and humor.\n","Score: 0.5610\tDocument: I liked the film it has what every horror likes in this type of movie the suspense,mystery,good and bad times,plus a shocking ending that makes you think that there is more to story, and plot was very good Robert.\n","Score: 0.5573\tDocument: The Scarletti Curse is absolutely wonderful. Ms. Feehan once again created a lively well written work that stand far apart from her Dark series (which I also adore). With complex and dark characters this book has quite a lot of bite and more than enough romance for a true fan of Christine's work. I highly recommend this book for one and all.\n","Score: 0.5525\tDocument: This book is amazing. I read it when I was a child and couldn't put it down. It has amazing adventure and suspense, without the horrible violence. Several months ago, something reminded me of the book and I had to hunt it down. I had forgotten the title and the author(it had been 15 years since I read it). I finally was able to locate it. I was thrilled. I bought it and read it in just a couple of hours. It is a book I recommend for both children and adults.\n","\n","\n","Query: Recommend a book with a plot twist.\n","Score: 0.6312\tDocument: The book was badly observed and shallow, with predictable and cliched plots. It made me want to throw up mostofthe time, and offered very little insight into the characters feelings. Do not read it unless you have to.\n","Score: 0.6036\tDocument: Boy, this was a disappointing read. The characters were not well developed (hence challenging to keep track of), the plot was implausible yet predictable, and half way through I had to wrestle with whether or not to even finish the book. I did, although it was unrewarding to do so.I'd rate this lower if I could.FYI, if you're looking for an alternate selection in the same genre, I highly recommend Silent Joe by T. Jefferson Parker.\n","Score: 0.6014\tDocument: This was a great book,I just could not put it down,and could not read it fast enough. Boy what a book the twist and turns in this just keeps you guessing and wanting to know what is going to happen next. This book makes you fall in love and can heat you up,it can also make you so angery. this book can make you go throu several of your emotions. This is a quick read romance. It is something that you will want to end your day off with if you read at night.\n","Score: 0.5920\tDocument: My english teacher assigned this book, one I would never read on my own. I am a 16 year old and I enjoy reading. But this book, while it does have a few good points and messages, is incredibly dull. The points are hard to get and I only understood the points after we had discussed them in class. While this book has a rather good story it`s concealed by endless symbols and references, I suggest the cliff notes version!!\n","Score: 0.5886\tDocument: I purchased this book expecting very good things. I found the plot very thin and predictable. There was very little suspense. It almost seemed like an abridged version of a book where all the detail leading up was left out. Also there didn't seem to be any character building or background to explain why these individuals would have such singleminded, and on the surface stupid, behaviour.\n","\n","\n"]}],"source":["from sentence_transformers import SentenceTransformer, util\n","from datasets import load_dataset\n","import torch\n","\n","# Load the pre-trained model from Hugging Face\n","model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n","model_sentence = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n","\n","# Load the Amazon Book Reviews dataset from Hugging Face\n","dataset = load_dataset(\"amazon_polarity\")\n","\n","# Use a smaller subset of the dataset\n","corpus = [entry['content'] for entry in dataset['train'].select(range(2000))]  # Adjust the range as needed\n","corpus_embeddings = model_sentence.encode(corpus, convert_to_tensor=True)\n","\n","# Sample queries related to book recommendations\n","queries = [\n","    \"Recommend me a book similar to '1984' by George Orwell.\",\n","    \"What are some good mystery novels?\",\n","    \"Can you suggest a romance book set in Paris?\",\n","    \"I'm looking for a fantasy book with dragons.\",\n","    \"Suggest a non-fiction book about history.\",\n","    \"What are some popular science fiction books?\",\n","    \"Recommend a thriller with a strong female lead.\",\n","    \"Can you suggest a children's book about adventure?\",\n","    \"I'm interested in books about artificial intelligence.\",\n","    \"What are some classic literature books I should read?\",\n","    \"Suggest a book that deals with mental health.\",\n","    \"Can you recommend a good autobiography?\",\n","    \"I'm looking for a humorous book.\",\n","    \"Suggest a book that has won a Pulitzer Prize.\",\n","    \"What are some good dystopian novels?\",\n","    \"Recommend a book that was turned into a movie.\",\n","    \"Can you suggest a young adult book series?\",\n","    \"I'm interested in books about space exploration.\",\n","    \"What are some good horror novels?\",\n","    \"Recommend a book with a plot twist.\"\n","]\n","\n","# Encode the queries\n","query_embeddings = model_sentence.encode(queries, convert_to_tensor=True)\n","\n","# Perform similarity search using dot product\n","for query, query_embedding in zip(queries, query_embeddings):\n","    # Compute cosine similarities\n","    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n","    \n","    # Find the top 5 most similar sentences\n","    top_results = torch.topk(cos_scores, k=5)\n","    \n","    print(f\"Query: {query}\")\n","    for score, idx in zip(top_results[0], top_results[1]):\n","        print(f\"Score: {score:.4f}\\tDocument: {corpus[idx]}\")\n","    print(\"\\n\")\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T10:25:38.647560Z","iopub.status.busy":"2024-06-18T10:25:38.646909Z","iopub.status.idle":"2024-06-18T10:25:38.652962Z","shell.execute_reply":"2024-06-18T10:25:38.652041Z","shell.execute_reply.started":"2024-06-18T10:25:38.647531Z"},"trusted":true},"outputs":[],"source":["def return_response(query, corpus):\n","    similarities = []\n","    for doc in corpus:\n","        cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n","        top_results = torch.topk(cos_scores, k=5)\n","    return corpus[top_result[1][0]]"]},{"cell_type":"markdown","metadata":{},"source":["#DOC\n","### Detailed Documentation\n","\n","This document provides a detailed description of the code that loads a pre-trained sentence transformer model, retrieves relevant documents from a dataset, and performs a similarity search for a set of sample queries.\n","\n","#### Importing Required Libraries\n","\n","```python\n","from sentence_transformers import SentenceTransformer, util\n","from datasets import load_dataset\n","import torch\n","```\n","\n","- **Purpose**: Import necessary libraries for loading models, handling datasets, and performing tensor computations.\n","  - `SentenceTransformer` and `util` from `sentence_transformers`: For encoding text and computing similarities.\n","  - `load_dataset` from `datasets`: For loading the dataset.\n","  - `torch`: For tensor operations and similarity calculations.\n","\n","#### Loading the Pre-trained Model\n","\n","```python\n","model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n","model_sentence = SentenceTransformer(model_name)\n","```\n","\n","- **Purpose**: Load a pre-trained sentence transformer model for encoding text.\n","  - **Model Name**: `sentence-transformers/all-MiniLM-L6-v2`.\n","\n","#### Loading and Preparing the Dataset\n","\n","```python\n","dataset = load_dataset(\"amazon_polarity\")\n","corpus = [entry['content'] for entry in dataset['train'].select(range(2000))]\n","corpus_embeddings = model_sentence.encode(corpus, convert_to_tensor=True)\n","```\n","\n","- **Purpose**: Load a dataset and prepare it for similarity search.\n","  - **Dataset**: Amazon Book Reviews from Hugging Face.\n","  - **Corpus Selection**: Use a subset of 2000 entries for efficient processing.\n","  - **Encoding**: Encode the corpus into dense vector representations using the loaded sentence transformer model.\n","\n","#### Defining Sample Queries\n","\n","```python\n","queries = [\n","    \"Recommend me a book similar to '1984' by George Orwell.\",\n","    \"What are some good mystery novels?\",\n","    \"Can you suggest a romance book set in Paris?\",\n","    \"I'm looking for a fantasy book with dragons.\",\n","    \"Suggest a non-fiction book about history.\",\n","    \"What are some popular science fiction books?\",\n","    \"Recommend a thriller with a strong female lead.\",\n","    \"Can you suggest a children's book about adventure?\",\n","    \"I'm interested in books about artificial intelligence.\",\n","    \"What are some classic literature books I should read?\",\n","    \"Suggest a book that deals with mental health.\",\n","    \"Can you recommend a good autobiography?\",\n","    \"I'm looking for a humorous book.\",\n","    \"Suggest a book that has won a Pulitzer Prize.\",\n","    \"What are some good dystopian novels?\",\n","    \"Recommend a book that was turned into a movie.\",\n","    \"Can you suggest a young adult book series?\",\n","    \"I'm interested in books about space exploration.\",\n","    \"What are some good horror novels?\",\n","    \"Recommend a book with a plot twist.\"\n","]\n","```\n","\n","- **Purpose**: Define a list of sample queries related to book recommendations for the similarity search.\n","\n","#### Encoding the Queries\n","\n","```python\n","query_embeddings = model_sentence.encode(queries, convert_to_tensor=True)\n","```\n","\n","- **Purpose**: Encode the sample queries into dense vector representations using the loaded sentence transformer model.\n","\n","#### Performing Similarity Search\n","\n","```python\n","for query, query_embedding in zip(queries, query_embeddings):\n","    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n","    top_results = torch.topk(cos_scores, k=5)\n","    \n","    print(f\"Query: {query}\")\n","    for score, idx in zip(top_results[0], top_results[1]):\n","        print(f\"Score: {score:.4f}\\tDocument: {corpus[idx]}\")\n","    print(\"\\n\")\n","```\n","\n","- **Purpose**: Perform a similarity search to find the most relevant documents for each query.\n","- **Process**:\n","  1. **Iterate through Queries**: For each query and its corresponding embedding.\n","  2. **Compute Similarity Scores**: Calculate cosine similarity scores between the query embedding and all corpus embeddings.\n","  3. **Identify Top Results**: Find the top 5 most similar documents based on the similarity scores.\n","  4. **Display Results**: Print the query, similarity scores, and corresponding documents.\n","\n","#### Summary\n","\n","This code provides a structured approach to:\n","1. Load and encode a dataset of book reviews.\n","2. Define a set of sample queries related to book recommendations.\n","3. Encode the queries using a pre-trained sentence transformer model.\n","4. Perform a similarity search to retrieve and display the most relevant documents from the corpus for each query."]},{"cell_type":"markdown","metadata":{"id":"9QDRcT-woxlW"},"source":["## 🎛️ Create a Generator\n","For this part, I practically handed you the whole code on a silver platter. 🍽️ But since we know you’re an explorer at heart and love trying new things, you can’t use the model I previously used. 😈 You have to try 3 different generators and compare them based on the quality of their answers. 🧪📊 [These might come in handy](https://huggingface.co/models?pipeline_tag=text-generation&sort=trending)."]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T10:25:38.654268Z","iopub.status.busy":"2024-06-18T10:25:38.654018Z","iopub.status.idle":"2024-06-18T10:33:08.762945Z","shell.execute_reply":"2024-06-18T10:33:08.759816Z","shell.execute_reply.started":"2024-06-18T10:25:38.654245Z"},"id":"iAPcSwlhui8L","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ec8ca8e245b2471b99aef744c63a98a2","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Deleted model directory: /root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2\n","Deleted tokenizer directory: /root/.cache/huggingface/hub/tokenizers--sentence-transformers--all-MiniLM-L6-v2\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"67279ab13e9341278ca09c83951f129e","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/663 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"143197320b2f47fe9dd88e476466c8ce","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/27.8k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"10e56a9c373741f5a84482013940c45c","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2669021070e94d6b84fea79336dacb7b","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00004.safetensors:   0%|          | 0.00/3.95G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4965541baf894bfb817912491cefb54e","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ba7fe67b540e4abca1345a95fed4d114","version_major":2,"version_minor":0},"text/plain":["model-00003-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8d762b7f84874fc791ab81d723add4c0","version_major":2,"version_minor":0},"text/plain":["model-00004-of-00004.safetensors:   0%|          | 0.00/3.56G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f91b61af79fe4456a8e8d8e6a4a36abf","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"48cceba8d2c244de97e068ff1940f024","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/243 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d9c21feca6134d1b8fd9cba1e5d7f813","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cb0e9363fd304395bf004a0cb7ae35c0","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"274b3d520b9b4018b9ffd1011dacbab7","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"78320f62de8849998b4cca77586fee70","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1659: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:426: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Model: Qwen/Qwen2-7B-Instruct\n","Response: You are a bot that makes recommendations for books. Try to be helpful recommender system.\n","This is the recommended activity: DAUGHTERS OF DARKNESS was the first book by L. J. Smith that Iread and I was hooked after that! I loved the way L. J. Smithdescribed all the characters, especialy Ash, and gave them all completely different personalities. This is, by far, one of the best books I've ever read and I can't wait for STRANGE FATE to come out. For anyone who is looking for another good series by L. J. Smith I suggest the Vampire Diaries and Dark Visions trilogies.\n","The user input is: Can you suggest a young adult book series?\n","Compile a recommendation to the user based on the recommended activity and the user input. Here's a recommendation for you:\n","\n","If you enjoyed \"Daughters of Darkness\" by L.J. Smith, you might also like the \"House of Night\" series by P.C. Cast and Kristin Cast. The series follows the life of Zoey Redbird, a 16-year-old girl who gets bitten by a vampyre during her senior year at an exclusive boarding school. The story explores themes of friendship, love, and self-discovery as Zoey navigates her new life as a half-vampyre.\n","\n","Just like in \"Daughters of Darkness,\" the authors create unique personalities for each character, making it easy to become invested in their stories. The series has several captivating plots that will keep you engaged from beginning to end. Plus, the world-building is impressive, offering a fresh take on the vampyre world.\n","\n","Another great series you might enjoy is \"The Selection\" by Kiera Cass. It's a romantic and thrilling tale set in a futuristic society where the prince must choose his future queen through a televised competition. The protagonist, America Singer, finds herself unexpectedly competing against girls from all over the country for the chance to win the prince's heart. The series combines elements of romance, drama, and suspense, making it a compelling read for fans of both genres.\n","\n","Both of these series offer engaging narratives, strong character development, and plenty of twists and turns that should satisfy your appetite for a good young adult book series. Enjoy exploring these fantastic reads!\n","\n","\n","Deleted model directory: /root/.cache/huggingface/hub/models--Qwen--Qwen2-7B-Instruct\n","Deleted tokenizer directory: /root/.cache/huggingface/hub/tokenizers--Qwen--Qwen2-7B-Instruct\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6ae131de0e934070a586dc9ffbb8a6c7","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/601 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"372a4c5a08d6494e9b93d6bb4071a9f1","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f491f28420294cb2b2e6772bafcdd679","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ede405b51050465c900e1b464aab600a","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e40c69cb225e4adaad6e6f737e904120","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"12a17482fc704915abfe88331643d44b","version_major":2,"version_minor":0},"text/plain":["model-00003-of-00003.safetensors:   0%|          | 0.00/4.55G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8f53411fb2a44e6aa3acecd57d3fa978","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"04a62e96c3664201b374de7265f0d2f9","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2078d4868c394dc3945194519e9ce751","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/137k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"65b08110b72742a2ad9c5b3766e3ee81","version_major":2,"version_minor":0},"text/plain":["tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"58158bd943504d3bad9a1e92bdebed55","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e96ec18fe2e4157af1e73d043f9c2f5","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1659: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Model: mistralai/Mistral-7B-Instruct-v0.3\n","Response: You are a bot that makes recommendations for books. Try to be helpful recommender system.\n","This is the recommended activity: DAUGHTERS OF DARKNESS was the first book by L. J. Smith that Iread and I was hooked after that! I loved the way L. J. Smithdescribed all the characters, especialy Ash, and gave them all completely different personalities. This is, by far, one of the best books I've ever read and I can't wait for STRANGE FATE to come out. For anyone who is looking for another good series by L. J. Smith I suggest the Vampire Diaries and Dark Visions trilogies.\n","The user input is: Can you suggest a young adult book series?\n","Compile a recommendation to the user based on the recommended activity and the user input. Here's my suggestion:\n","If you're searching for an immersive and captivating young adult book series, I highly recommend starting with \"Dark Visions\" by L. J. Smith. This thrilling trilogy features rich characters, fascinating plotlines, and a depth of storytelling that's sure to keep you turning the pages. Another brilliant series from L. J. Smith you might enjoy is the \"Vampire Diaries\" – a captivating exploration of love, mystery, and darkness that has enchanted readers for years. If you've already given both series a read and are looking for something similar, don't miss \"Daughters of Darkness\". This series serves as an excellent introduction to L. J. Smith's captivating world-building and character development. With the latest book, \"Strange Fate\", recently released, now is the perfect time to dive in!\n","\n","\n","Deleted model directory: /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3\n","Deleted tokenizer directory: /root/.cache/huggingface/hub/tokenizers--mistralai--Mistral-7B-Instruct-v0.3\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0a75af27ff7742369084094713329c63","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a32d0f379be64d1ea5f155a4ba7cafa0","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a2aa2ec52acd4b21b287177d0b8cd567","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bf6d1b64979240b5bb922c7a8d7933b6","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9ef772281896489bb745bfbf3aaa2584","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d28d10ad86c4cee9a364ca0e346148a","version_major":2,"version_minor":0},"text/plain":["model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"991812413f34496887bfe19a31754eeb","version_major":2,"version_minor":0},"text/plain":["model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6cc78e25f7ba4104a0c4303668a13636","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"025a9b096bec4834b06d13a80000f316","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76a3690d17f0493aa27a0990d6ed6430","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d76c33cf2e2c4587968ccf5641698dc1","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d79992a88ee488a87a695d6a7934f66","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1659: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Model: meta-llama/Meta-Llama-3-8B-Instruct\n","Response: You are a bot that makes recommendations for books. Try to be helpful recommender system.\n","This is the recommended activity: DAUGHTERS OF DARKNESS was the first book by L. J. Smith that Iread and I was hooked after that! I loved the way L. J. Smithdescribed all the characters, especialy Ash, and gave them all completely different personalities. This is, by far, one of the best books I've ever read and I can't wait for STRANGE FATE to come out. For anyone who is looking for another good series by L. J. Smith I suggest the Vampire Diaries and Dark Visions trilogies.\n","The user input is: Can you suggest a young adult book series?\n","Compile a recommendation to the user based on the recommended activity and the user input. \n","\n","Here's my response:\n","\n","Hi there! I'm happy to help you find your next great read. Since you loved the Vampire Diaries series by L. J. Smith, I think you might enjoy other young adult book series with similar themes and supernatural elements. Here are a few recommendations:\n","\n","1. The Mortal Instruments by Cassandra Clare - This series follows Clary Fray as she discovers a world of demons, vampires, and Shadowhunters in modern-day New York City.\n","2. The Infernal Devices by Cassandra Clare - This prequel series to The Mortal Instruments is set in the 19th century and follows Tessa Gray as she uncovers a world of Shadowhunters and demons in London.\n","3. The Iron Fey by Julie Kagawa - This series follows Meghan Chase as she navigates a world of faeries and the Iron Kingdom, where the Seelie and Unseelie Courts are at war.\n","4. The Blue Bloods by Melissa de la Cruz - This series follows Schuyler Van Alen as she discovers she's a Blue Blood, a vampire with a long history, and must navigate the world of the undead in modern-day New York City.\n","5. The Nightshade series by Andrea Cremer - This series follows Calla Tor as she becomes embroiled in a world of werewolves and vampires in a small town in the Pacific Northwest.\n","\n","All of these series have a similar blend of supernatural elements, romance, and adventure that made the Vampire Diaries series so compelling. I hope you find a new favorite series among these recommendations! Happy reading!\n","\n","\n","Deleted model directory: /root/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3-8B-Instruct\n","Deleted tokenizer directory: /root/.cache/huggingface/hub/tokenizers--meta-llama--Meta-Llama-3-8B-Instruct\n"]}],"source":["from transformers import AutoModelForCausalLM, AutoTokenizer , BitsAndBytesConfig\n","import shutil\n","import gc # garbage collect library\n","import torch\n","# Define function to generate responses\n","def generate_response(model, tokenizer, input_text):\n","    inputs = tokenizer.encode(input_text, return_tensors='pt')\n","    outputs = model.generate(inputs, max_new_tokens= 500, num_return_sequences=1, do_sample=True, top_k=50)\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","quantization_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n",")\n","\n","# Load the models and tokenizers\n","models = [\n","    'Qwen/Qwen2-7B-Instruct',\n","'mistralai/Mistral-7B-Instruct-v0.3',\n","    'meta-llama/Meta-Llama-3-8B-Instruct'\n","]\n","def retrieve_relevant_document(query, corpus_embeddings):\n","    cos_scores = util.pytorch_cos_sim(query, corpus_embeddings)[0]\n","    top_result = torch.topk(cos_scores, k=1)\n","    return corpus[top_result[1][0]]\n","\n","# Sample query and top retrieved document\n","input_user = \"Can you suggest a young adult book series?\"\n","input_user_embeddings = model_sentence.encode(input_user, convert_to_tensor=True)\n","relevant_document = retrieve_relevant_document(input_user_embeddings , corpus_embeddings)\n","\n","# clear GPU & CPU\n","del model_sentence\n","\n","gc.collect()\n","\n","torch.cuda.empty_cache()\n","# Path to the cached model directory\n","\n","model_dir = f\"/root/.cache/huggingface/hub/models--{model_name.replace('/', '--')}\"\n","\n","\n","\n","# Remove the directory\n","\n","shutil.rmtree(model_dir, ignore_errors=True)\n","\n","\n","\n","# Optionally, also remove the tokenizer directory if it's separate\n","\n","tokenizer_dir = f\"/root/.cache/huggingface/hub/tokenizers--{model_name.replace('/', '--')}\"\n","\n","shutil.rmtree(tokenizer_dir, ignore_errors=True)\n","\n","\n","\n","print(f\"Deleted model directory: {model_dir}\")\n","\n","print(f\"Deleted tokenizer directory: {tokenizer_dir}\")\n","\n","\n","\n","prompt = \"\"\"You are a bot that makes recommendations for books. Try to be helpful recommender system.\n","This is the recommended activity: {relevant_document}\n","The user input is: {user_input}\n","Compile a recommendation to the user based on the recommended activity and the user input.\"\"\"\n","prompt = prompt.replace(\"{relevant_document}\", relevant_document).replace(\"{user_input}\", input_user)\n","\n","# Generate responses using the models\n","for model_name in models:\n","    model = AutoModelForCausalLM.from_pretrained(model_name , quantization_config=quantization_config,\n","    device_map=\"auto\")\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    input_text = prompt\n","\n","    # Generate response\n","    response = generate_response(model, tokenizer, input_text)\n","\n","    # Print results\n","    print(f\"Model: {model_name}\")\n","    print(f\"Response: {response}\")\n","    print(\"\\n\")\n","\n","    # clear GPU & CPU\n","    del model\n","    \n","    gc.collect()\n","\n","    torch.cuda.empty_cache()\n","    # Path to the cached model directory\n","\n","    model_dir = f\"/root/.cache/huggingface/hub/models--{model_name.replace('/', '--')}\"\n","\n","\n","\n","    # Remove the directory\n","\n","    shutil.rmtree(model_dir, ignore_errors=True)\n","\n","\n","\n","    # Optionally, also remove the tokenizer directory if it's separate\n","\n","    tokenizer_dir = f\"/root/.cache/huggingface/hub/tokenizers--{model_name.replace('/', '--')}\"\n","\n","    shutil.rmtree(tokenizer_dir, ignore_errors=True)\n","\n","\n","\n","    print(f\"Deleted model directory: {model_dir}\")\n","\n","    print(f\"Deleted tokenizer directory: {tokenizer_dir}\")"]},{"cell_type":"markdown","metadata":{},"source":["Sure! Below is a detailed explanation of the provided code.\n","\n","---\n","\n","### Explanation of the Code\n","\n","This code demonstrates how to use various large language models (LLMs) to generate responses based on user input, perform document retrieval, and handle model caching efficiently. The code includes several key steps:\n","\n","1. **Importing Libraries**:\n","    ```python\n","    from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n","    import shutil\n","    import gc\n","    import torch\n","    ```\n","    - `transformers`: Provides classes and functions to load pre-trained language models and tokenizers.\n","    - `shutil`: Used for file operations such as deleting directories.\n","    - `gc`: The garbage collection library to manage memory usage.\n","    - `torch`: PyTorch library for tensor computations.\n","\n","2. **Defining the Function to Generate Responses**:\n","    ```python\n","    def generate_response(model, tokenizer, input_text):\n","        inputs = tokenizer.encode(input_text, return_tensors='pt')\n","        outputs = model.generate(inputs, max_new_tokens=500, num_return_sequences=1, do_sample=True, top_k=50)\n","        return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    ```\n","    - This function encodes the input text using the tokenizer, generates a response using the model, and decodes the output back into human-readable text.\n","\n","3. **Quantization Configuration**:\n","    ```python\n","    quantization_config = BitsAndBytesConfig(\n","        load_in_4bit=True,\n","        bnb_4bit_use_double_quant=True,\n","        bnb_4bit_quant_type=\"nf4\",\n","    )\n","    ```\n","    - This configuration sets up quantization to reduce the memory footprint of the models, making them more efficient to load and run.\n","\n","4. **Model and Tokenizer Loading**:\n","    ```python\n","    models = [\n","        'Qwen/Qwen2-7B-Instruct',\n","        'mistralai/Mistral-7B-Instruct-v0.3',\n","        'meta-llama/Meta-Llama-3-8B-Instruct'\n","    ]\n","    ```\n","\n","5. **Document Retrieval Function**:\n","    ```python\n","    def retrieve_relevant_document(query, corpus_embeddings):\n","        cos_scores = util.pytorch_cos_sim(query, corpus_embeddings)[0]\n","        top_result = torch.topk(cos_scores, k=1)\n","        return corpus[top_result[1][0]]\n","    ```\n","    - This function retrieves the most relevant document from a corpus based on cosine similarity scores between the query and the corpus embeddings.\n","\n","6. **Sample Query and Top Retrieved Document**:\n","    ```python\n","    input_user = \"Can you suggest a young adult book series?\"\n","    input_user_embeddings = model_sentence.encode(input_user, convert_to_tensor=True)\n","   "]},{"cell_type":"markdown","metadata":{"id":"t10lJ43nrn4r"},"source":["## 📊 Evaluate the results\n","Here, you’ve got to put those 3 models to the test. Use the 20 queries you’ve created on each of the 3 models. Now you’ll have 20 tuples, each containing five items: user input, selected document, and 3 responses from three different models. Use a judge model on each tuple to select the best answer. 🥇 The judge model can be any language model accessible on the internet, whether you find one on Hugging Face or use one through an API. 🌐 Finally, calculate the score for each model, which is how many times the judge picked that model. 🏆"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T10:33:08.767880Z","iopub.status.busy":"2024-06-18T10:33:08.767503Z","iopub.status.idle":"2024-06-18T10:33:16.123827Z","shell.execute_reply":"2024-06-18T10:33:16.123024Z","shell.execute_reply.started":"2024-06-18T10:33:08.767851Z"},"id":"rNAU2pnMpljY","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7a3987d0ef2a42ed88a530b6e2d005c3","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/914 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5db3121cc16f44e1ab325d5a8781ee78","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/20 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6d77c864e21541389bce202f7e522c8f","version_major":2,"version_minor":0},"text/plain":["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"617d6531af7e43b796c35a0869dae313","version_major":2,"version_minor":0},"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ae769597255438480b7e5e5c5ea8756","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"72ee9465910249a9a3c6114300d91f74","version_major":2,"version_minor":0},"text/plain":["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b00e00e4f1174490ab004a43a72cc0fc","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"57f3d576a9374e8ebd7be75ba2ad0e9b","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d3ef60425c3c4be181d547882a3725b3","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"94889a5e7a3646c0a32b409bc1c7f59a","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8f9b7b87bd034da09d36a6be4ffe20af","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6549b7e0967a4378b82f2ccf1a4d33d8","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"74eb9451e91d4aa99e63057875215927","version_major":2,"version_minor":0},"text/plain":["1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"10d356f750374973bbac2e327ae652cb","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/63 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Function to retrieve the most relevant document\n","def retrieve_relevant_document(query, corpus_embeddings):\n","    query_embedding = model_sentence.encode(query, convert_to_tensor=True)\n","    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n","    top_result = torch.topk(cos_scores, k=1)\n","    return corpus[top_result[1][0]]\n","\n","# Define function to generate responses\n","def generate_response(model, tokenizer, input_text):\n","    inputs = tokenizer.encode(input_text, return_tensors='pt')\n","    outputs = model.generate(inputs, max_new_tokens=500, num_return_sequences=1, do_sample=True, top_k=50)\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","# Load the custom dataset from Hugging Face\n","dataset_queries = load_dataset(\"soltaniali/RAGG\")\n","\n","# Extract the queries from the dataset\n","queries = [entry['query'] for entry in dataset_queries['train']]\n","# Encode the queries\n","model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n","model_sentence = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n","# query_embeddings = model_sentence.encode(queries, convert_to_tensor=True)\n","# Use a smaller subset of the dataset\n","corpus = [entry['content'] for entry in dataset['train'].select(range(2000))]  # Adjust the range as needed\n","corpus_embeddings = model_sentence.encode(corpus, convert_to_tensor=True)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T10:33:16.125348Z","iopub.status.busy":"2024-06-18T10:33:16.125063Z","iopub.status.idle":"2024-06-18T10:57:51.230165Z","shell.execute_reply":"2024-06-18T10:57:51.228290Z","shell.execute_reply.started":"2024-06-18T10:33:16.125324Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f988750bbdd0456aac1d734172e8e351","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/663 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0e0cb45180824c2f98b9558686d130bb","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/27.8k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e3e6039f1cfb4e41a8d212e093d9cbbc","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"642a84a2e4d5483197cb31132aea1704","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00004.safetensors:   0%|          | 0.00/3.95G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bf15872364364dcfa99ac77c2ceb6dfa","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fedaa130d7294c6fa265b8c7ed94c1b2","version_major":2,"version_minor":0},"text/plain":["model-00003-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"886c897b9bde4822800f50873b1f715b","version_major":2,"version_minor":0},"text/plain":["model-00004-of-00004.safetensors:   0%|          | 0.00/3.56G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1428f23105b44cdeb71008d839821aeb","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c655c9f6cdbb4acabbb0c91b3f9bb738","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/243 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9fa1ac034f624d66baab97f53d58b528","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e1bd9447b07a4136b869961c9cb1867f","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"94ab9ba09a704d8a92bb3e5921f6e0af","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8ad09ffd9829449ca91768e16152fc9a","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b2334c1fd28549539e78a0f2d8e0d679","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1659: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"39a3be5ecabb4c77a462deca14f67b85","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1659: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ec33601742f46c39fc3d718a0361ff6","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"02cf2f010872428e88758e7b87e24f41","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ac446a57ce54481bbd9c6945cc218fd0","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0d1f6747b3b4476bac8f75698db90138","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f1fb380f7bba4ce5a0838a0635b62c09","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a399b78c21884ec08900b39702eb8463","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c9c6fa5f4405483aa0576c0b6498a3c0","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5f5550636506499d9cde12b873c78839","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8d33156a3c114250942cb06631d72348","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4ead9011dfb349a1a06b5decdb7109a1","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ed07ea9f4254518b1bd8500e37a0aae","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ea4c2584131c4a8581174c79b1883464","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e4f0537f8dcb445cbc370c90caaae1ab","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fde970f9fdf140cda787edb169f56b4b","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5701760c44fa4e52bef717a8a82e29d4","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bc0851a494274e1f8a49c7751924fcc8","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"85c6521c1f8040a893922d6692f366b9","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6b1ba1d9010641c38817205221d756ff","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"70cb958f5dcb496f8f8e5f23a7a391e8","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/601 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a6bed60fadfa4c88a64e03acfb0ddec4","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c0087712562849329d18ad396e883592","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"44058a75a001454b904818015a465ecb","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"816339e7cc224124beb43ee8c35bda4a","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ad716b87cba3468f96ae36d8a0bcd472","version_major":2,"version_minor":0},"text/plain":["model-00003-of-00003.safetensors:   0%|          | 0.00/4.55G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b20d5da01c24b01958904fd09a6ce22","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b5385302c21947cfae0bec9188d9e29d","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8b595cff3b304c599d81e7e0aa99b83d","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/137k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"53edb6682e76470e93a7e2902beb65d6","version_major":2,"version_minor":0},"text/plain":["tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a7e31fadd6d046d8ae8a1bcc39f1e30d","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bce9b6fa86b648d38e080ecb22f72646","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3e6c8c6af0df476f9f2643b19cc6937a","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2bbf87aff9f144918ca5ec448938d8f3","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1659: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"12af16c4cc2f4268aa950d16d8f8e3d4","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"27426832eb7d41309421ba5622ba2dc0","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"802decb25c0b4f7daa60f14c96f9e262","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"367c9cc2f1504e468daed3ef72e2f814","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ffe306a9504d4afa9a481b17ac07c51f","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4b969dad973544579c771613c6989bf6","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dfae6f2c1e6e46b8ae3727c3813ec1dd","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2ca68a99fc2d429ea10827fca3ed92ee","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"75020b97c7a64a52b591b1a7f23d92d7","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"242fb347b7664db98446a1f6ded3f3d9","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"16f15da2acf04a5ba2cbb7d5101ec75d","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"03c6ca2a9d4444278c431dacd2c39600","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a165d8c693e242b7b84d6df9af484f9c","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3ea70924e9b24bd5aae686335ed90e3f","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c0cf13fdbcce4c88a0246cede3d129c3","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"12036d229f5b46f0820bbfabb10c4a0e","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b25c7a94a1c4f3492b5fd9704b3ee78","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"53211e3f77454b33b02cec06d9cd116a","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a215edcda9084e8b89ebbe56a074b308","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8a555ab271fc4d17ae63695d1011cb32","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1fbac0c799c24d6fa1962553356fbec0","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b8382e3d0924169997bef278ab2fe7c","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e16517dcbd747c186102d7616d4d02f","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"316e21e08f6045219e9704bbe3483aaa","version_major":2,"version_minor":0},"text/plain":["model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4a626c4e5e0e403ab146445ae7b0cc2d","version_major":2,"version_minor":0},"text/plain":["model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0810c238b89041de86a0f4967dfe826f","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cb52d90db33843f3a65a3247966d452b","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0c103ed188974271a0645011276344b4","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1fa5b6e287eb484db1e5bec95b1f50e5","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e0319ab0f4ff446a805698a56d4546eb","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc90e2f8b23d4b81a02513d1f0550a98","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f35ac8aef7b8400d86c9460f346ea505","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1659: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"444a4890e68f40979d84d34a46a807e2","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c2cd0db03d2c4db191fb22d0aa98d6ea","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5572f3bdc0ac4b6da2df890b3a005043","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"044fe95eac9f4f8f94aeeba9c3f48ab7","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ac15acfd1a5a4e5fa6bb67a60036c14a","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af7870145642434f84a8a818e61e85ba","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a6cfe6747b674070ae1c74c56f0edead","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7161a0a776b7494489f40f9fc2dc476c","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7d1ef5ad16844070a69d0f3d2f4a39c0","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"29f30d05da8c44879200cb5b9ccfc325","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d8e493485c4d477380f88bed8dcd608e","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a08f68be3dad4bc9b1fca601e4797f39","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ee71756f3a3846cea18ef168e3bd67cc","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3a011b3336cf484e8cd014aece33c2ae","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dae0306568ea40ba88872dbcebaaaad6","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"046474b5648d4474b7a16decabbdf3f7","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4b89a1e5f3bf4d278352e98fa15b7855","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d5efb0eb989f4a279c953018f2d0d372","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]}],"source":["# Generate responses for each query using each model\n","responses = {query: {} for query in queries}\n","for model_name in models:\n","    model = AutoModelForCausalLM.from_pretrained(model_name , quantization_config=quantization_config,\n","    device_map=\"auto\")\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    for query in queries:\n","        relevant_document = retrieve_relevant_document(query, corpus_embeddings)\n","        prompt = f\"You are a bot that makes recommendations for books. Try to be a helpful recommender system.\\nThis is the recommended activity: {relevant_document}\\nThe user input is: {query}\\nCompile a recommendation to the user based on the recommended activity and the user input.\"\n","\n","\n","        response = generate_response(model, tokenizer, prompt)\n","        responses[query][model_name] = response\n","\n","    # Clear GPU & CPU memory\n","    del model\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","    # Path to the cached model directory\n","    model_dir = f\"/root/.cache/huggingface/hub/models--{model_name.replace('/', '--')}\"\n","    shutil.rmtree(model_dir, ignore_errors=True)\n","\n","    # Optionally, also remove the tokenizer directory if it's separate\n","    tokenizer_dir = f\"/root/.cache/huggingface/hub/tokenizers--{model_name.replace('/', '--')}\"\n","    shutil.rmtree(tokenizer_dir, ignore_errors=True)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T11:05:15.861793Z","iopub.status.busy":"2024-06-18T11:05:15.860958Z","iopub.status.idle":"2024-06-18T11:05:24.631080Z","shell.execute_reply":"2024-06-18T11:05:24.630099Z","shell.execute_reply.started":"2024-06-18T11:05:15.861750Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Scores:\n","Qwen/Qwen2-7B-Instruct: 15\n","Qwen/Qwen2-7B-Instruct: 15\n","mistralai/Mistral-7B-Instruct-v0.3: 2\n","mistralai/Mistral-7B-Instruct-v0.3: 2\n","meta-llama/Meta-Llama-3-8B-Instruct: 3\n","meta-llama/Meta-Llama-3-8B-Instruct: 3\n"]}],"source":["from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n","# Load the judge model for sequence classification\n","# Load the judge model for sequence classification\n","judge_model = AutoModelForSequenceClassification.from_pretrained('roberta-base')\n","judge_tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n","judge = pipeline(\"text-classification\", model=judge_model, tokenizer=judge_tokenizer)\n","\n","# Function to evaluate and select the best response\n","def judge_best_response(query, responses):\n","    inputs = [\n","        f\"Query: {query}\\nResponse: {responses[model_name]}\\n\"[:512] for model_name in responses\n","    ]\n","    results = judge(inputs)\n","    best_response_idx = max(range(len(results)), key=lambda idx: results[idx]['score'])\n","    best_model = list(responses.keys())[best_response_idx]\n","    return best_model\n","\n","# Evaluate the responses and calculate the scores\n","scores = {model_name: 0 for model_name in models}\n","for query in queries:\n","    best_model = judge_best_response(query, responses[query])\n","    scores[best_model] += 1\n","\n","# Print the scores\n","print(\"Scores:\")\n","for model_name, score in scores.items():\n","    print(f\"{model_name}: {score}\")\n","    print(f\"{model_name}: {score}\")"]},{"cell_type":"markdown","metadata":{},"source":["#DOC\n","### Detailed Documentation\n","\n","This document describes the functionality and purpose of specific segments within the provided Python code, which demonstrates the process of retrieving relevant documents, generating responses, and evaluating the best responses using large language models (LLMs).\n","\n","#### Retrieving the Most Relevant Document\n","\n","```python\n","def retrieve_relevant_document(query, corpus_embeddings):\n","    query_embedding = model_sentence.encode(query, convert_to_tensor=True)\n","    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n","    top_result = torch.topk(cos_scores, k=1)\n","    return corpus[top_result[1][0]]\n","```\n","\n","- **Purpose**: This function identifies and retrieves the most relevant document from a given corpus based on a query.\n","- **Process**:\n","  1. **Encoding**: The input query is encoded into a dense vector using a pre-trained sentence transformer model.\n","  2. **Similarity Calculation**: Cosine similarity scores between the encoded query and corpus embeddings are computed.\n","  3. **Top Result Identification**: The document with the highest cosine similarity score is identified.\n","  4. **Return Document**: The most relevant document from the corpus is returned.\n","\n","#### Generating Responses\n","\n","```python\n","def generate_response(model, tokenizer, input_text):\n","    inputs = tokenizer.encode(input_text, return_tensors='pt')\n","    outputs = model.generate(inputs, max_new_tokens=500, num_return_sequences=1, do_sample=True, top_k=50)\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","```\n","\n","- **Purpose**: This function generates a response to a given input text using a specified model and tokenizer.\n","- **Process**:\n","  1. **Tokenization**: The input text is tokenized into a format suitable for the model.\n","  2. **Response Generation**: The model generates a response based on the tokenized input.\n","  3. **Decoding**: The generated response is decoded from token format to human-readable text.\n","  4. **Return Response**: The decoded response is returned.\n","\n","#### Loading and Processing the Dataset\n","\n","```python\n","dataset_queries = load_dataset(\"soltaniali/RAGG\")\n","\n","queries = [entry['query'] for entry in dataset_queries['train']]\n","model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n","model_sentence = SentenceTransformer(model_name)\n","corpus = [entry['content'] for entry in dataset['train'].select(range(2000))]\n","corpus_embeddings = model_sentence.encode(corpus, convert_to_tensor=True)\n","```\n","\n","- **Purpose**: This segment loads and processes a custom dataset from Hugging Face, extracting queries and corpus content, and encoding them for later use.\n","- **Process**:\n","  1. **Dataset Loading**: The custom dataset is loaded from Hugging Face.\n","  2. **Query Extraction**: Queries are extracted from the dataset.\n","  3. **Model Initialization**: A pre-trained sentence transformer model is initialized.\n","  4. **Corpus Selection**: A subset of the dataset is selected to form the corpus.\n","  5. **Encoding**: Both queries and corpus contents are encoded into dense vectors using the sentence transformer model.\n","\n","#### Generating Responses for Each Query\n","\n","```python\n","responses = {query: {} for query in queries}\n","for model_name in models:\n","    model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=quantization_config, device_map=\"auto\")\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    for query in queries:\n","        relevant_document = retrieve_relevant_document(query, corpus_embeddings)\n","        prompt = f\"You are a bot that makes recommendations for books. Try to be a helpful recommender system.\\nThis is the recommended activity: {relevant_document}\\nThe user input is: {query}\\nCompile a recommendation to the user based on the recommended activity and the user input.\"\n","        response = generate_response(model, tokenizer, prompt)\n","        responses[query][model_name] = response\n","\n","    # Clear GPU & CPU memory\n","    del model\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","    # Path to the cached model directory\n","    model_dir = f\"/root/.cache/huggingface/hub/models--{model_name.replace('/', '--')}\"\n","    shutil.rmtree(model_dir, ignore_errors=True)\n","    tokenizer_dir = f\"/root/.cache/huggingface/hub/tokenizers--{model_name.replace('/', '--')}\"\n","    shutil.rmtree(tokenizer_dir, ignore_errors=True)\n","```\n","\n","- **Purpose**: This segment generates responses for each query using different models and clears resources to maintain efficiency.\n","- **Process**:\n","  1. **Initialization**: Responses dictionary is initialized to store responses for each query.\n","  2. **Model Loading**: Each model from the list of models is loaded with quantization configurations for efficiency.\n","  3. **Query Processing**: For each query:\n","     - **Document Retrieval**: The most relevant document is retrieved from the corpus.\n","     - **Prompt Creation**: A prompt is created by incorporating the relevant document and the query.\n","     - **Response Generation**: A response is generated using the model and tokenizer.\n","     - **Response Storage**: The generated response is stored in the responses dictionary.\n","  4. **Resource Cleanup**: After processing each model, resources are cleaned up by deleting the model and clearing caches.\n","\n","#### Evaluating Responses\n","\n","```python\n","judge_model = AutoModelForSequenceClassification.from_pretrained('roberta-base')\n","judge_tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n","judge = pipeline(\"text-classification\", model=judge_model, tokenizer=judge_tokenizer)\n","\n","def judge_best_response(query, responses):\n","    inputs = [f\"Query: {query}\\nResponse: {responses[model_name]}\\n\"[:512] for model_name in responses]\n","    results = judge(inputs)\n","    best_response_idx = max(range(len(results)), key=lambda idx: results[idx]['score'])\n","    best_model = list(responses.keys())[best_response_idx]\n","    return best_model\n","\n","scores = {model_name: 0 for model_name in models}\n","for query in queries:\n","    best_model = judge_best_response(query, responses[query])\n","    scores[best_model] += 1\n","\n","print(\"Scores:\")\n","for model_name, score in scores.items():\n","    print(f\"{model_name}: {score}\")\n","```\n","\n","- **Purpose**: This segment evaluates the generated responses to identify and score the best-performing model for each query.\n","- **Process**:\n","  1. **Judge Model Initialization**: A sequence classification model is loaded and initialized as a text classification pipeline.\n","  2. **Best Response Evaluation**: A function is defined to evaluate responses:\n","     - **Input Preparation**: Inputs are prepared by concatenating the query and each model's response.\n","     - **Model Evaluation**: The judge model evaluates each response.\n","     - **Best Response Selection**: The response with the highest score is identified.\n","  3. **Score Calculation**: For each query, the best model is determined and scores are updated.\n","  4. **Score Printing**: The final scores for each model are printed, indicating their performance across all queries."]},{"cell_type":"markdown","metadata":{"id":"NHQTDDUApxXt"},"source":["### Now that I'm writing this message, it's 3 in the morning and I'm tired as fox. So I hope you've learned something from this project and someday you use what you've learned here in a real-case scenario. Good Luck! ✌️"]},{"cell_type":"markdown","metadata":{},"source":["#CHATGPT HISTORY:\n","\n","https://chatgpt.com/share/e13a6ea8-9872-474d-83d6-96a9de8a443e\n","\n","https://chatgpt.com/share/8a88d0bd-ac21-4620-919a-b1a75e6b3d32\n","\n","https://chatgpt.com/share/06781b6e-0a3b-4f3f-9ea1-be25d6d010f5\n","\n","https://chatgpt.com/share/7a7f5d78-4dc8-498b-bac1-c585f22b92ee\n","\n","https://chatgpt.com/share/fc771389-12cc-4306-ba16-5dea88054955"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"004588b776e44d30a062508032d973b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d148fee98174eef8628328f73a2dae3","placeholder":"​","style":"IPY_MODEL_249aec38b0514ad092354a92be2ac813","value":"tokenizer.model: 100%"}},"00d171f2515e4a99941dccce0b880db3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"031b19eeff0441fca6574cf07da92371":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"041c673732684fadaa7bff986d933526":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6dedbe5963444cbd84a7c4e2196b2bfe","placeholder":"​","style":"IPY_MODEL_d756b759dc7a4105bbd1234986556ee5","value":"added_tokens.json: 100%"}},"052ad9cc510d482c8fa07c9e80ece598":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05bd5d649b4e480b8a0649db83a624b2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0620fda80e36439db89bf94c9e8b9a25":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cc0e5d7c1f84c2c9509e354c2b208e7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cdc558997ef4d4b908579568dbe37c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0db620afa09f487081e294c0e29b2d54":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0eae0055584846198ebf9585d041cf79":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1004ea8ba2a748caa30ee0b8f6bdf04c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c660d20e950348a4978b448a5bc358e1","placeholder":"​","style":"IPY_MODEL_14d0c6cd851a433b92824b1b6f58b3a0","value":"model-00002-of-00002.safetensors: 100%"}},"1032f8cb7e9c4a5790dbbffe472d7238":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"14d0c6cd851a433b92824b1b6f58b3a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"162cb47b55944df8b81318761b6c8b60":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6b5113ce36674206b30dfb0b8ca50b15","IPY_MODEL_bf17ae3347944664a0a5ea580479c3fc","IPY_MODEL_21b86c087bd4485abe3b78dfd29ba580"],"layout":"IPY_MODEL_9dc4864e73e24b73944064302de87d80"}},"16e44cffb07143119e7b77e62cca27c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f6eea78dc7c14a3783cf35a69d4c43e3","IPY_MODEL_2a0709b5d8d24f9c87dc86bd1eea2e6f","IPY_MODEL_6ebe02adfed44fc8b36319cc03e06c8e"],"layout":"IPY_MODEL_5ffbe6c9def64d8797f8de9f0af9a79c"}},"1ac3645d77af485f9015e23e6df174ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d8d8ee1f0b64b8ab9b1d02391373d47":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_855bb723485448acbfe88cfdc2fee482","max":172,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3166215280164c8f9949840bf50eec67","value":172}},"1e864dfe67eb4da5b43bc17d177f4acd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21b86c087bd4485abe3b78dfd29ba580":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5366f461d0ba465fad3a880dfe9fd930","placeholder":"​","style":"IPY_MODEL_ec30acf53d6b41609b9b234842850219","value":" 16.3k/16.3k [00:00&lt;00:00, 975kB/s]"}},"249aec38b0514ad092354a92be2ac813":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28341f6d10f34dbb93111d7a8d3cb730":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a0709b5d8d24f9c87dc86bd1eea2e6f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6e69696d0844d09a1c46f6c9648ace4","max":568,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f6a67777ab2b425c8fd301188606f5b4","value":568}},"2adeabc3244d4cd683532701815ab9a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2d37b7f7312d48dd8ee6351062219759":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3166215280164c8f9949840bf50eec67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"34ac6ae0852b43498c032f5843c23449":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d37b7f7312d48dd8ee6351062219759","placeholder":"​","style":"IPY_MODEL_c3ab62b3820f49bf8be266770e7ec06c","value":"configuration_phi3.py: 100%"}},"38a987a9ab9a40439865b39d29431ac0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39519e4f5ad045d6ba13b11c39ebaeaf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e2105c5dd1941a79d8f9d7e3188cdb9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e885f22a8f644b8abd2a49224789049":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad527ab674a741aeb0f30f0e1708a570","placeholder":"​","style":"IPY_MODEL_7a488562cc6c4dcab36d8051e1c7549c","value":" 2/2 [01:07&lt;00:00, 31.51s/it]"}},"3ec65b841a15419cb1d6dc039fe457c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bef9341a69a34cacae0fa7e2ba8117e1","placeholder":"​","style":"IPY_MODEL_c5330e0df04e4077930b08951b0bc89e","value":" 2.67G/2.67G [00:20&lt;00:00, 178MB/s]"}},"4380b92f37c14b7b8c880af9931fbe03":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45abbd6a116e47fb872c98ef2208575c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ce834fd2c474f9c9661cefec24356be","max":73778,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2adeabc3244d4cd683532701815ab9a1","value":73778}},"465f5ac16bd74b88b16b4bd7ff5c9497":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bf2c4ed8a744cdfa4b3381108387320":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e3183d233104001a078a7acc59d461b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83cd503bd2a349a4a5fe88360b07dd9a","placeholder":"​","style":"IPY_MODEL_38a987a9ab9a40439865b39d29431ac0","value":"tokenizer.json: 100%"}},"4fc9df483d6c4a2b9fd9c3fb47db12ba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"500ab28d94954102a240202d8884d427":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5022a47bf4b0424d83030ef119ed4a35":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51d28ab174794051b126fdea66f09381":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0620fda80e36439db89bf94c9e8b9a25","max":4972489328,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bd678dbfb551408f89498f08b7ddf48a","value":4972489328}},"5366f461d0ba465fad3a880dfe9fd930":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55195d9004964d02899f6f500b03a6e9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55928b40843b4b78b53388872fb628ea":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57a53b6c7f084f98b72628c2b0bd8216":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b6098cf2752477fa723e6715a3ae93a","placeholder":"​","style":"IPY_MODEL_052ad9cc510d482c8fa07c9e80ece598","value":"modeling_phi3.py: 100%"}},"57f4c95712b1442891dd898a9771e464":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"587c82c504dd4d55bd1fec639a857977":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d859e8d736541d5bb0c0b5b2235517a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ffbe6c9def64d8797f8de9f0af9a79c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6332da23b5be461baeb9e73f7127b04e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_55195d9004964d02899f6f500b03a6e9","max":499723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_57f4c95712b1442891dd898a9771e464","value":499723}},"680142323be24b9893ab81ac28d2086e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"69921d76b1bb4abe9108febcaf9ab86a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb62e196c3ec46608bfffeaa59838a87","placeholder":"​","style":"IPY_MODEL_bc122f0792c142f88cd05618b990b8d8","value":"generation_config.json: 100%"}},"6a85fc3710d64488b7fc7cf0bd06bd7f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_34ac6ae0852b43498c032f5843c23449","IPY_MODEL_ba099ffa38b8446ab54948377c9cd57c","IPY_MODEL_d55aeabf73e5415bbe1cc70ede979d90"],"layout":"IPY_MODEL_818c89d1c4e24ce5a96688a75a1ef985"}},"6b5113ce36674206b30dfb0b8ca50b15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd8d7a0cb4464c1a8b867accf9eae933","placeholder":"​","style":"IPY_MODEL_db15e86f51c744a7812814e07bbb3bcc","value":"model.safetensors.index.json: 100%"}},"6dedbe5963444cbd84a7c4e2196b2bfe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e619e5265d94d5583862b13334ca37b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ebe02adfed44fc8b36319cc03e06c8e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94cec2b157404cbab8a489c79f33123c","placeholder":"​","style":"IPY_MODEL_1e864dfe67eb4da5b43bc17d177f4acd","value":" 568/568 [00:00&lt;00:00, 32.7kB/s]"}},"70aa8f072c6e498db64fc35a156206bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_55928b40843b4b78b53388872fb628ea","max":2669692552,"min":0,"orientation":"horizontal","style":"IPY_MODEL_680142323be24b9893ab81ac28d2086e","value":2669692552}},"7320ada7a0114dab9c8ddf4595ce709e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee9062db0d5345b3b602d300f6f98306","placeholder":"​","style":"IPY_MODEL_4bf2c4ed8a744cdfa4b3381108387320","value":" 500k/500k [00:00&lt;00:00, 28.1MB/s]"}},"73e1e3c76a5e44b180f0fef76a80a9d4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"774c63a738ab4beebafe4c7d0fe9f69f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77f1c06cedfb49db8e4ebaed8c6eb358":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c6340eddece44c559b4941705be86f97","IPY_MODEL_ee97a406ecd341b4a9164a6020ca608f","IPY_MODEL_3e885f22a8f644b8abd2a49224789049"],"layout":"IPY_MODEL_500ab28d94954102a240202d8884d427"}},"7a488562cc6c4dcab36d8051e1c7549c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a80370d3cb247ebbea40bf0c368e255":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d5a53e67539e440583eec9e3297f7b18","IPY_MODEL_e178feca94d44a259c521397688eed1f","IPY_MODEL_c2e1653910504797a190f355c66db5ed"],"layout":"IPY_MODEL_9cc7bc78839d4c3db3682cad996a26cf"}},"7b6098cf2752477fa723e6715a3ae93a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e729063f4694a05aca30fa31ffbc787":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00d171f2515e4a99941dccce0b880db3","placeholder":"​","style":"IPY_MODEL_e43f8e723c18441e9f1ae2173f681c61","value":" 172/172 [00:00&lt;00:00, 12.2kB/s]"}},"7fd8b7cb971d4a1c8332dd6e4a641f0b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_980f65caa8334b878f8282a90f13de14","placeholder":"​","style":"IPY_MODEL_0cdc558997ef4d4b908579568dbe37c4","value":" 73.8k/73.8k [00:00&lt;00:00, 5.00MB/s]"}},"818c89d1c4e24ce5a96688a75a1ef985":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8270f14ba69c43c8b2a9703aebd8adb8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83cd503bd2a349a4a5fe88360b07dd9a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"855bb723485448acbfe88cfdc2fee482":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8630bf07eff04738b54801e84fd6e184":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b377b60174f9429a9228c3fcaebae39c","placeholder":"​","style":"IPY_MODEL_d6a8bce40f4c4adb9c9319b2a1f4d5e0","value":"Loading checkpoint shards: 100%"}},"86a216e0a1d64b5e9b88460d353913fa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"897415366b444ba7b8c3b5eeb06710b8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cceb776ab1a42b4ae9876428d059dc4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_465f5ac16bd74b88b16b4bd7ff5c9497","placeholder":"​","style":"IPY_MODEL_587c82c504dd4d55bd1fec639a857977","value":" 3.35k/3.35k [00:00&lt;00:00, 252kB/s]"}},"8d148fee98174eef8628328f73a2dae3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8df04aab0fb440e3b84bc9e3fda8ab64":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e74c41b5b0c4872a9ce649fd064ca62":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90d5f36c957e4822813b121e98bddc97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3227be7dc8147e189f8fa2c6d24ae1b","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9669836ab33a40c7ae7991d3ef16113e","value":2}},"91c7afa2441a4d0a95ae19e9a4a70645":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9378640159204d25b55089113febef6e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94cec2b157404cbab8a489c79f33123c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"962f23bbd63048b998c7a9d9a3e2dc10":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5aa191ad0a345ca81b22c79d39c12aa","placeholder":"​","style":"IPY_MODEL_774c63a738ab4beebafe4c7d0fe9f69f","value":" 293/293 [00:00&lt;00:00, 16.9kB/s]"}},"9669836ab33a40c7ae7991d3ef16113e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"980f65caa8334b878f8282a90f13de14":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"987ebfb8506c4e4bb9284e1c6cdfb6a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_041c673732684fadaa7bff986d933526","IPY_MODEL_f4b84138d28a42db8093c78574c3323a","IPY_MODEL_962f23bbd63048b998c7a9d9a3e2dc10"],"layout":"IPY_MODEL_05bd5d649b4e480b8a0649db83a624b2"}},"9a45c2158d2c4b83a8b7200608d4ac4f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a8fc7bcdc414a5dbb285a8a1d27cd25":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cb8568853da42c8859c1479545fafd6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a45c2158d2c4b83a8b7200608d4ac4f","placeholder":"​","style":"IPY_MODEL_c1932b58fb424bb18554fbff43083c39","value":" 2/2 [00:33&lt;00:00, 15.70s/it]"}},"9cc7bc78839d4c3db3682cad996a26cf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ce834fd2c474f9c9661cefec24356be":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9dc4864e73e24b73944064302de87d80":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5d4ac6578364e81bca94e1dba188e3e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6e69696d0844d09a1c46f6c9648ace4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8d62d58186e4c17b96449478f6476ef":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a950e1b94e924a928cba29a14f5f0a94":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa0d6e653b8f4b71b6d8fe01428ea88f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c39b392cead34ad2b24c1ce5ddd1c8bb","IPY_MODEL_b0dfc3120c2241d586db487ada828e71","IPY_MODEL_8cceb776ab1a42b4ae9876428d059dc4"],"layout":"IPY_MODEL_bbdc226d8946488896286c4fd5c1a7c9"}},"aae84e4dd7af41f493aff6e04aab2e90":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e74c41b5b0c4872a9ce649fd064ca62","placeholder":"​","style":"IPY_MODEL_0eae0055584846198ebf9585d041cf79","value":" 1.84M/1.84M [00:00&lt;00:00, 36.5MB/s]"}},"ad527ab674a741aeb0f30f0e1708a570":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0b01b506bba4006b81da6c7b39630d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_004588b776e44d30a062508032d973b7","IPY_MODEL_6332da23b5be461baeb9e73f7127b04e","IPY_MODEL_7320ada7a0114dab9c8ddf4595ce709e"],"layout":"IPY_MODEL_73e1e3c76a5e44b180f0fef76a80a9d4"}},"b0dfc3120c2241d586db487ada828e71":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a8fc7bcdc414a5dbb285a8a1d27cd25","max":3353,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e0b1bd3bf9984a82b28e9981d443fb0d","value":3353}},"b1a5b800a62f41c095a2e1dba18fbd3f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b377b60174f9429a9228c3fcaebae39c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b97e42ee535b47228ba5ade29486ef64":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba099ffa38b8446ab54948377c9cd57c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5d4ac6578364e81bca94e1dba188e3e","max":10411,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1032f8cb7e9c4a5790dbbffe472d7238","value":10411}},"bbdc226d8946488896286c4fd5c1a7c9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc122f0792c142f88cd05618b990b8d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc2452b8820a4d3ca2e77ecd47f49c08":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8630bf07eff04738b54801e84fd6e184","IPY_MODEL_90d5f36c957e4822813b121e98bddc97","IPY_MODEL_9cb8568853da42c8859c1479545fafd6"],"layout":"IPY_MODEL_b1a5b800a62f41c095a2e1dba18fbd3f"}},"bd678dbfb551408f89498f08b7ddf48a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bef9341a69a34cacae0fa7e2ba8117e1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf17ae3347944664a0a5ea580479c3fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e2105c5dd1941a79d8f9d7e3188cdb9","max":16331,"min":0,"orientation":"horizontal","style":"IPY_MODEL_28341f6d10f34dbb93111d7a8d3cb730","value":16331}},"c1932b58fb424bb18554fbff43083c39":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2e1653910504797a190f355c66db5ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9378640159204d25b55089113febef6e","placeholder":"​","style":"IPY_MODEL_d82c8a449db240aa993ed906f5e32880","value":" 3.18k/3.18k [00:00&lt;00:00, 203kB/s]"}},"c39b392cead34ad2b24c1ce5ddd1c8bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d500823ecf1c41e88c4d0f4f8f584071","placeholder":"​","style":"IPY_MODEL_ed917a614dd64ed9a5c46d31d6ca74c1","value":"config.json: 100%"}},"c3ab62b3820f49bf8be266770e7ec06c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c5330e0df04e4077930b08951b0bc89e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c5aa191ad0a345ca81b22c79d39c12aa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6340eddece44c559b4941705be86f97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0fee34ef1304249bf635afbfd253f0f","placeholder":"​","style":"IPY_MODEL_b97e42ee535b47228ba5ade29486ef64","value":"Downloading shards: 100%"}},"c65ce0ba141745dfac30f53e6d862fc5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c660d20e950348a4978b448a5bc358e1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6612f66dc51428ab4a0abdb90e8791d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8d62d58186e4c17b96449478f6476ef","placeholder":"​","style":"IPY_MODEL_a950e1b94e924a928cba29a14f5f0a94","value":" 4.97G/4.97G [00:47&lt;00:00, 34.4MB/s]"}},"cd8d7a0cb4464c1a8b867accf9eae933":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0fee34ef1304249bf635afbfd253f0f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d500823ecf1c41e88c4d0f4f8f584071":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d55aeabf73e5415bbe1cc70ede979d90":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8270f14ba69c43c8b2a9703aebd8adb8","placeholder":"​","style":"IPY_MODEL_e03ed1c834cd4e7c814d52eab2fbb430","value":" 10.4k/10.4k [00:00&lt;00:00, 754kB/s]"}},"d5a53e67539e440583eec9e3297f7b18":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4fc9df483d6c4a2b9fd9c3fb47db12ba","placeholder":"​","style":"IPY_MODEL_e3de92fd49c64c699e4868a6b946a795","value":"tokenizer_config.json: 100%"}},"d6a8bce40f4c4adb9c9319b2a1f4d5e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d756b759dc7a4105bbd1234986556ee5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d82c8a449db240aa993ed906f5e32880":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d973ef85a8e74e4ca5477522cc083fc4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db15e86f51c744a7812814e07bbb3bcc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db610c4e5ae34b41afbd1a50cc972469":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_57a53b6c7f084f98b72628c2b0bd8216","IPY_MODEL_45abbd6a116e47fb872c98ef2208575c","IPY_MODEL_7fd8b7cb971d4a1c8332dd6e4a641f0b"],"layout":"IPY_MODEL_5d859e8d736541d5bb0c0b5b2235517a"}},"dd797b33a8ca430bb06ed52c0289724e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_69921d76b1bb4abe9108febcaf9ab86a","IPY_MODEL_1d8d8ee1f0b64b8ab9b1d02391373d47","IPY_MODEL_7e729063f4694a05aca30fa31ffbc787"],"layout":"IPY_MODEL_86a216e0a1d64b5e9b88460d353913fa"}},"de2253234ddd4e9a973e715e058bf456":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_39519e4f5ad045d6ba13b11c39ebaeaf","max":1844419,"min":0,"orientation":"horizontal","style":"IPY_MODEL_91c7afa2441a4d0a95ae19e9a4a70645","value":1844419}},"df021be2b59943d3a2e123f27b5af357":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4e3183d233104001a078a7acc59d461b","IPY_MODEL_de2253234ddd4e9a973e715e058bf456","IPY_MODEL_aae84e4dd7af41f493aff6e04aab2e90"],"layout":"IPY_MODEL_1ac3645d77af485f9015e23e6df174ad"}},"e03ed1c834cd4e7c814d52eab2fbb430":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e0b1bd3bf9984a82b28e9981d443fb0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e178feca94d44a259c521397688eed1f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5022a47bf4b0424d83030ef119ed4a35","max":3181,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0db620afa09f487081e294c0e29b2d54","value":3181}},"e3227be7dc8147e189f8fa2c6d24ae1b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3de92fd49c64c699e4868a6b946a795":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e43f8e723c18441e9f1ae2173f681c61":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6e73602990e4955ab509b5fadd1fcad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec30acf53d6b41609b9b234842850219":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eced50764c5d4b1d978a48b025505146":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed917a614dd64ed9a5c46d31d6ca74c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee9062db0d5345b3b602d300f6f98306":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee97a406ecd341b4a9164a6020ca608f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8df04aab0fb440e3b84bc9e3fda8ab64","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_031b19eeff0441fca6574cf07da92371","value":2}},"f2d67925578f4a7b8e587aca4b3032e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc25d899108e487d98cde38b0af8f208","IPY_MODEL_51d28ab174794051b126fdea66f09381","IPY_MODEL_c6612f66dc51428ab4a0abdb90e8791d"],"layout":"IPY_MODEL_0cc0e5d7c1f84c2c9509e354c2b208e7"}},"f3370099e84f499fbb20ac3601929107":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1004ea8ba2a748caa30ee0b8f6bdf04c","IPY_MODEL_70aa8f072c6e498db64fc35a156206bb","IPY_MODEL_3ec65b841a15419cb1d6dc039fe457c3"],"layout":"IPY_MODEL_897415366b444ba7b8c3b5eeb06710b8"}},"f4b84138d28a42db8093c78574c3323a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6e73602990e4955ab509b5fadd1fcad","max":293,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c65ce0ba141745dfac30f53e6d862fc5","value":293}},"f6a67777ab2b425c8fd301188606f5b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f6eea78dc7c14a3783cf35a69d4c43e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e619e5265d94d5583862b13334ca37b","placeholder":"​","style":"IPY_MODEL_eced50764c5d4b1d978a48b025505146","value":"special_tokens_map.json: 100%"}},"fb62e196c3ec46608bfffeaa59838a87":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc25d899108e487d98cde38b0af8f208":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4380b92f37c14b7b8c880af9931fbe03","placeholder":"​","style":"IPY_MODEL_d973ef85a8e74e4ca5477522cc083fc4","value":"model-00001-of-00002.safetensors: 100%"}}}}},"nbformat":4,"nbformat_minor":4}
